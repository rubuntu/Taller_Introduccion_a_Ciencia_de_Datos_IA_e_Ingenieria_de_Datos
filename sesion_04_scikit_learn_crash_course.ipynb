{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubuntu/Taller_Introduccion_a_Ciencia_de_Datos_IA_e_Ingenieria_de_Datos/blob/main/sesion_04_scikit_learn_crash_course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c058839f-c7b4-4ddd-b756-691018e82e27",
      "metadata": {
        "id": "c058839f-c7b4-4ddd-b756-691018e82e27",
        "lines_to_next_cell": 0
      },
      "source": [
        "# Crash Course de Machine Learning con Scikit-learn\n",
        "\n",
        "Este curso tiene como objetivo brindar una introducción rápida y práctica a las técnicas principales de Machine Learning utilizando Scikit-learn. Cubriremos clasificación, regresión, clustering, preprocesamiento, reducción de dimensiones, métricas de evaluación y gráficos, así como técnicas como la partición de datasets en entrenamiento y validación.\n",
        "\n",
        "---\n",
        "\n",
        "## Contenido\n",
        "\n",
        "1. **Clasificación**\n",
        "2. **Regresión**\n",
        "3. **Clustering**\n",
        "4. **Preprocesamiento**\n",
        "5. **Reducción de Dimensiones**\n",
        "6. **Métricas y Gráficos**\n",
        "7. **Partición del Dataset**\n",
        "\n",
        "---\n",
        "\n",
        "## Diagrama de Algoritmos\n",
        "\n",
        "A continuación se muestra un diagrama que resume las opciones de algoritmos en Scikit-learn, basado en la cantidad de datos, el tipo de tarea y otras características.\n",
        "\n",
        "![Scikit-learn Algorithm Cheat Sheet](https://scikit-learn.org/stable/_downloads/b82bf6cd7438a351f19fac60fbc0d927/ml_map.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa13e0d0-0c1a-41b2-abb3-8fe75a81b4a3",
      "metadata": {
        "id": "aa13e0d0-0c1a-41b2-abb3-8fe75a81b4a3",
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "\n",
        "## 1. Clasificación\n",
        "\n",
        "La clasificación se utiliza para predecir etiquetas categóricas. Por ejemplo, clasificar correos como spam o no spam.\n",
        "\n",
        "### Algoritmos comunes\n",
        "- **Regresión logística**\n",
        "- **Árboles de decisión**\n",
        "- **Random Forest**\n",
        "- **SVM (Support Vector Machine)**\n",
        "- **Naive Bayes**\n",
        "\n",
        "### Métricas de evaluación\n",
        "- **Accuracy:** Proporción de predicciones correctas.\n",
        "- **Precision, Recall y F1-Score:** Métricas útiles para conjuntos desbalanceados.\n",
        "- **Matriz de confusión:** Representación visual del desempeño.\n",
        "\n",
        "### Código básico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5bba7a4",
      "metadata": {
        "id": "f5bba7a4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Cargar el dataset Iris\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo Random Forest\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Imprimir reporte de clasificación\n",
        "print(\"Reporte de Clasificación:\")\n",
        "print(classification_report(y_test, predictions, target_names=iris.target_names))\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Crear una matriz de confusión más bonita\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title(\"Matriz de Confusión\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Verdadero\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "239a1655-1b88-435c-8894-5c6a067da8ba",
      "metadata": {
        "id": "239a1655-1b88-435c-8894-5c6a067da8ba"
      },
      "source": [
        "### Explicación:\n",
        "\n",
        "1. **`classification_report`**:\n",
        "   - Este informe muestra métricas clave para evaluar el rendimiento de un modelo de clasificación:\n",
        "     - **Precisión (Precision):** Porcentaje de predicciones positivas correctas sobre todas las predicciones positivas.\n",
        "     - **Exhaustividad (Recall o Sensitivity):** Porcentaje de verdaderos positivos detectados entre todos los casos reales positivos.\n",
        "     - **F1-Score:** Media armónica de la precisión y el recall, equilibrando ambas métricas.\n",
        "     - **Support:** Número de ocurrencias de cada clase en los datos reales.\n",
        "\n",
        "2. **`confusion_matrix`**:\n",
        "   - La matriz de confusión ilustra el número de predicciones correctas e incorrectas hechas por el modelo:\n",
        "     - Las filas representan las clases reales.\n",
        "     - Las columnas representan las clases predichas.\n",
        "     - Los valores diagonales indican predicciones correctas (verdaderos positivos).\n",
        "\n",
        "### Matriz de confusión:\n",
        "En el gráfico, los datos reales están en el eje vertical (etiqueta \"Verdadero\"), y las predicciones están en el eje horizontal (etiqueta \"Predicción\"). Cada celda contiene el número de muestras que fueron clasificadas como cada combinación de clase real y predicha. El uso de colores facilita la visualización de los resultados.\n",
        "\n",
        "Por ejemplo:\n",
        "- La clase \"setosa\" fue correctamente clasificada 10 veces.\n",
        "- La clase \"versicolor\" fue correctamente clasificada 9 veces.\n",
        "- La clase \"virginica\" fue correctamente clasificada 11 veces.\n",
        "\n",
        "Esto refleja un excelente rendimiento del modelo para este conjunto de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3270b590-e181-452b-9438-7d4910b50bcf",
      "metadata": {
        "id": "3270b590-e181-452b-9438-7d4910b50bcf"
      },
      "source": [
        "### **Dataset Iris**\n",
        "El dataset **Iris** es uno de los conjuntos de datos más conocidos y utilizados en el aprendizaje automático y estadística. Fue introducido por el botánico **Ronald A. Fisher** en 1936 y contiene información sobre tres especies de flores del género *Iris*:\n",
        "\n",
        "1. **Iris-setosa**  \n",
        "2. **Iris-versicolor**  \n",
        "3. **Iris-virginica**\n",
        "\n",
        "El objetivo del dataset es clasificar las flores en estas tres especies basándose en sus características físicas.\n",
        "\n",
        "---\n",
        "\n",
        "### **Características del dataset**\n",
        "- **Número de muestras:** 150 (50 por cada especie de flor).\n",
        "- **Características (features):**\n",
        "  1. Longitud del sépalo (*sepal length*, en cm).\n",
        "  2. Ancho del sépalo (*sepal width*, en cm).\n",
        "  3. Longitud del pétalo (*petal length*, en cm).\n",
        "  4. Ancho del pétalo (*petal width*, en cm).\n",
        "- **Etiqueta objetivo (target):** Especies de las flores (*setosa*, *versicolor*, *virginica*).\n",
        "\n",
        "---\n",
        "\n",
        "### **Propósito del dataset**\n",
        "El dataset Iris se utiliza principalmente en problemas de:\n",
        "1. **Clasificación:** Predecir la especie de una flor con base en sus características físicas.\n",
        "2. **Visualización:** Es ideal para demostrar técnicas como reducción de dimensionalidad, ya que tiene solo cuatro características.\n",
        "3. **Pruebas de modelos:** Se utiliza como un primer paso para probar algoritmos de clasificación y clustering, dado su tamaño reducido y simplicidad.\n",
        "\n",
        "---\n",
        "\n",
        "### **Ejemplo de Uso**\n",
        "Supongamos que queremos clasificar las flores usando las características del sépalo y pétalo. Este dataset es ideal debido a que las especies tienen cierta separación natural basada en las dimensiones de sus características.\n",
        "\n",
        "Por ejemplo:\n",
        "- **Iris-setosa** es fácilmente distinguible porque tiene pétalos más cortos y sépalos más anchos.\n",
        "- **Iris-versicolor** y **Iris-virginica** tienen características más similares, lo que las hace más difíciles de clasificar, siendo un desafío para algunos modelos.\n",
        "\n",
        "En resumen, el dataset Iris es un excelente punto de partida para aprender sobre clasificación supervisada y análisis exploratorio de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fe1b842-7467-4fe7-a17f-26644c786d9a",
      "metadata": {
        "id": "1fe1b842-7467-4fe7-a17f-26644c786d9a"
      },
      "source": [
        "### Explicación de las métricas\n",
        "\n",
        "El **F1-Score** es una métrica utilizada en clasificación para equilibrar dos aspectos clave del rendimiento de un modelo: la **precisión (precision)** y la **exhaustividad (recall)**.\n",
        "\n",
        "#### Fórmula del F1-Score:\n",
        "$$\n",
        "F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "$$\n",
        "\n",
        "Donde:\n",
        "- **Precision** es la proporción de predicciones positivas correctas entre todas las predicciones positivas realizadas:\n",
        "  $$\n",
        "  \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
        "  $$\n",
        "  (TP: verdaderos positivos, FP: falsos positivos).\n",
        "\n",
        "- **Recall** es la proporción de predicciones positivas correctas entre todos los casos positivos reales:\n",
        "  $$\n",
        "  \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
        "  $$\n",
        "  (FN: falsos negativos).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42d721a5",
      "metadata": {
        "id": "42d721a5",
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "\n",
        "## 2. Regresión\n",
        "\n",
        "La regresión se utiliza para predecir valores continuos, como precios o temperaturas.\n",
        "\n",
        "### Algoritmos comunes\n",
        "- **Regresión lineal**\n",
        "- **Elastic Net**\n",
        "- **Random Forest Regressor**\n",
        "- **SVR (Support Vector Regressor)**\n",
        "\n",
        "### Métricas de evaluación\n",
        "- **MSE (Error Cuadrático Medio):** Promedio de los errores al cuadrado.\n",
        "- **RMSE (Raíz del MSE):** Medida más interpretable en unidades originales.\n",
        "- **R² (Coeficiente de determinación):** Proporción de la varianza explicada.\n",
        "\n",
        "### Código básico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9067ef28",
      "metadata": {
        "id": "9067ef28"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar el dataset Boston Housing\n",
        "boston = fetch_openml(data_id=531, as_frame=True)\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "# Convertir todas las columnas a numéricas, si es necesario\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "y = pd.to_numeric(y)\n",
        "\n",
        "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo de regresión lineal\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluación del modelo\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R² Score: {r2:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f50baf51-880c-4480-ada3-85b26fd608bb",
      "metadata": {
        "id": "f50baf51-880c-4480-ada3-85b26fd608bb"
      },
      "source": [
        "### Dataset: Boston Housing (cargado desde `sklearn.datasets`)\n",
        "El dataset de precios de viviendas en Boston (Boston Housing) es un conjunto de datos comúnmente usado en problemas de regresión. Contiene características como el número de habitaciones, la edad de las viviendas, o la distancia a zonas de empleo, con el objetivo de predecir el valor medio de las casas en miles de dólares.\n",
        "\n",
        "---\n",
        "\n",
        "### Explicación de las métricas de evaluación:\n",
        "1. **Mean Squared Error (MSE)**:\n",
        "   - Mide el promedio de los errores al cuadrado entre las predicciones y los valores reales.\n",
        "   - Fórmula:\n",
        "     $$\n",
        "     \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
        "     $$\n",
        "     Donde $y_i$ son los valores reales y $\\hat{y}_i$ son las predicciones.\n",
        "   - Valores más bajos indican un mejor ajuste.\n",
        "\n",
        "2. **R² Score (Coeficiente de Determinación)**:\n",
        "   - Mide qué tan bien las predicciones explican la variabilidad en los datos reales.\n",
        "   - Fórmula:\n",
        "     $$\n",
        "     R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
        "     $$\n",
        "     Donde $\\bar{y}$ es el promedio de los valores reales.\n",
        "   - Un $R^2 = 1$ indica un ajuste perfecto. Un $R^2 < 0$ sugiere un modelo que no es útil.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Interpretación del Ejemplo\n",
        "- **Mean Squared Error (MSE):** Nos indica el error promedio al cuadrado entre los valores reales y las predicciones. Un MSE bajo refleja que las predicciones están cerca de los valores reales.\n",
        "- **R² Score:** Nos muestra qué tan bien el modelo explica la variabilidad en los datos. Un \\(R^2\\) cercano a 1 indica que el modelo captura casi toda la variabilidad.\n",
        "\n",
        "Este código utiliza el dataset **Boston Housing**, un conjunto de datos realista para problemas de regresión, y evalúa el desempeño del modelo usando métricas estándar."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3064b227",
      "metadata": {
        "id": "3064b227",
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Clustering\n",
        "\n",
        "El clustering es una técnica de aprendizaje no supervisado que agrupa datos en clusters basados en similitudes.\n",
        "\n",
        "### Algoritmos comunes\n",
        "- **K-Means**\n",
        "- **DBSCAN**\n",
        "- **Gaussian Mixture Models (GMM)**\n",
        "\n",
        "### Métricas de evaluación\n",
        "- **Silhouette Score:** Mide la cohesión y separación de clusters.\n",
        "- **Inertia:** Suma de las distancias cuadráticas dentro de cada cluster.\n",
        "\n",
        "### Código básico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "034a5272",
      "metadata": {
        "id": "034a5272"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Cargar el dataset Iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Aplicar KMeans para crear 3 clusters\n",
        "model = KMeans(n_clusters=3, random_state=42)\n",
        "clusters = model.fit_predict(X)\n",
        "\n",
        "# Calcular el Silhouette Score\n",
        "sil_score = silhouette_score(X, clusters)\n",
        "print(f\"Silhouette Score: {sil_score:.2f}\")\n",
        "\n",
        "# Reducir dimensiones a 2D usando PCA para graficar\n",
        "pca = PCA(n_components=2)\n",
        "X_reduced = pca.fit_transform(X)\n",
        "\n",
        "# Crear un scatter plot de los clusters\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(\n",
        "    x=X_reduced[:, 0], y=X_reduced[:, 1], hue=clusters, palette=\"viridis\", s=100, alpha=0.8\n",
        ")\n",
        "plt.title(\"Clusters generados por KMeans en el dataset Iris\")\n",
        "plt.xlabel(\"Componente Principal 1\")\n",
        "plt.ylabel(\"Componente Principal 2\")\n",
        "plt.legend(title=\"Cluster\", loc=\"upper right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73a8bfb5-94d0-4928-adac-6d222f41b08c",
      "metadata": {
        "id": "73a8bfb5-94d0-4928-adac-6d222f41b08c"
      },
      "source": [
        "### Explicación del código:\n",
        "\n",
        "1. **Dataset Iris**:\n",
        "   - Este dataset contiene 150 muestras de flores con 4 características (longitud y ancho del sépalo, longitud y ancho del pétalo).\n",
        "   - El objetivo en este caso no es clasificar, sino identificar patrones de agrupamiento entre las muestras.\n",
        "\n",
        "2. **KMeans**:\n",
        "   - Es un algoritmo de clustering no supervisado que divide los datos en un número predefinido de grupos (clusters). Aquí elegimos 3 clusters, porque conocemos que hay 3 especies de flores.\n",
        "\n",
        "3. **Silhouette Score**:\n",
        "   - Es una métrica que evalúa la calidad del clustering:\n",
        "     - Valores cercanos a 1 indican clusters bien separados y compactos.\n",
        "     - Valores cercanos a 0 indican solapamiento entre clusters.\n",
        "     - El valor obtenido de **0.55** sugiere que el modelo genera clusters razonables, pero no perfectos.\n",
        "\n",
        "4. **PCA (Reducción de Dimensiones)**:\n",
        "   - Reducimos las 4 dimensiones del dataset Iris a 2 para poder visualizar los clusters en un gráfico 2D.\n",
        "\n",
        "5. **Gráfico**:\n",
        "   - Los puntos representan las muestras del dataset.\n",
        "   - Cada color indica un cluster generado por KMeans.\n",
        "   - Las componentes principales 1 y 2 (PC1 y PC2) son ejes generados por PCA que explican la mayor variación en los datos.\n",
        "\n",
        "Este análisis ilustra cómo agrupar datos usando KMeans y evaluar el resultado con el Silhouette Score, además de presentar los clusters de manera intuitiva."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ba8210",
      "metadata": {
        "id": "36ba8210",
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "\n",
        "## 4. Preprocesamiento\n",
        "\n",
        "### Técnicas comunes\n",
        "- **Estandarización:** Escalar datos para tener media 0 y desviación estándar 1.\n",
        "- **Codificación categórica:** One-hot encoding o Label Encoding.\n",
        "- **Imputación:** Rellenar valores faltantes.\n",
        "\n",
        "### Código básico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f12f7905",
      "metadata": {
        "id": "f12f7905"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03ee9a49",
      "metadata": {
        "id": "03ee9a49",
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "\n",
        "## 5. Reducción de Dimensiones\n",
        "\n",
        "La reducción de dimensiones simplifica datasets de alta dimensionalidad, conservando la mayor cantidad de información posible.\n",
        "\n",
        "### Técnicas comunes\n",
        "- **PCA (Análisis de Componentes Principales)**\n",
        "- **t-SNE**\n",
        "- **Isomap**\n",
        "\n",
        "### Código básico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3807af61",
      "metadata": {
        "id": "3807af61"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_reduced = pca.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28a90ddd-1253-4706-a7d2-154b3f00d973",
      "metadata": {
        "id": "28a90ddd-1253-4706-a7d2-154b3f00d973",
        "lines_to_next_cell": 0
      },
      "source": [
        "---\n",
        "\n",
        "## 6. Métricas y Gráficos\n",
        "\n",
        "### Para clasificación\n",
        "- **Matriz de confusión**\n",
        "- **Curvas ROC-AUC:** Evalúan el desempeño para múltiples umbrales.\n",
        "\n",
        "### Para regresión\n",
        "- **Gráficos de predicción vs valores reales**\n",
        "\n",
        "---\n",
        "\n",
        "### Código ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e40870d-3692-4cf5-8ccc-5d2f33d82ccc",
      "metadata": {
        "id": "4e40870d-3692-4cf5-8ccc-5d2f33d82ccc"
      },
      "outputs": [],
      "source": [
        "# Importar las librerías necesarias\n",
        "from sklearn.datasets import load_breast_cancer, load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configuración global de estilo\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# ========== CLASIFICACIÓN BINARIA: Breast Cancer Dataset ==========\n",
        "\n",
        "# Cargar el dataset Breast Cancer\n",
        "breast_cancer = load_breast_cancer()\n",
        "X_class = breast_cancer.data\n",
        "y_class = breast_cancer.target\n",
        "\n",
        "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
        "    X_class, y_class, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Entrenar un modelo de clasificación (Random Forest)\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train_class, y_train_class)\n",
        "y_pred_class = clf.predict(X_test_class)\n",
        "y_prob_class = clf.predict_proba(X_test_class)[:, 1]\n",
        "\n",
        "# Métrica: Matriz de Confusión\n",
        "conf_matrix_class = confusion_matrix(y_test_class, y_pred_class)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(\n",
        "    conf_matrix_class,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=breast_cancer.target_names,\n",
        "    yticklabels=breast_cancer.target_names,\n",
        ")\n",
        "plt.title(\"Matriz de Confusión (Clasificación Binaria - Breast Cancer)\")\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Valor Real\")\n",
        "plt.show()\n",
        "\n",
        "# Métrica: Curva ROC-AUC\n",
        "fpr, tpr, _ = roc_curve(y_test_class, y_prob_class)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\", color=\"blue\")\n",
        "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")\n",
        "plt.title(\"Curva ROC-AUC (Clasificación Binaria - Breast Cancer)\")\n",
        "plt.xlabel(\"Tasa de Falsos Positivos\")\n",
        "plt.ylabel(\"Tasa de Verdaderos Positivos\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# ========== REGRESIÓN: Diabetes Dataset ==========\n",
        "\n",
        "# Cargar el dataset Diabetes\n",
        "diabetes = load_diabetes()\n",
        "X_reg = diabetes.data\n",
        "y_reg = diabetes.target\n",
        "\n",
        "# Dividir el dataset en conjuntos de entrenamiento y prueba\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Entrenar un modelo de regresión (Linear Regression)\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train_reg, y_train_reg)\n",
        "y_pred_reg = reg.predict(X_test_reg)\n",
        "\n",
        "# Gráfico de Predicción vs Valores Reales\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(\n",
        "    y_test_reg,\n",
        "    y_pred_reg,\n",
        "    alpha=0.7,\n",
        "    edgecolors=\"k\",\n",
        "    label=\"Predicciones\",\n",
        ")\n",
        "plt.plot(\n",
        "    [y_test_reg.min(), y_test_reg.max()],\n",
        "    [y_test_reg.min(), y_test_reg.max()],\n",
        "    color=\"red\",\n",
        "    linestyle=\"--\",\n",
        "    label=\"Línea Ideal\",\n",
        ")\n",
        "plt.title(\"Gráfico de Predicción vs Valores Reales (Regresión - Diabetes)\")\n",
        "plt.xlabel(\"Valores Reales\")\n",
        "plt.ylabel(\"Predicciones\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Métricas de evaluación para regresión\n",
        "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R² Score: {r2:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ed878e2-76fd-4f87-9ad8-7c9944982a4f",
      "metadata": {
        "id": "5ed878e2-76fd-4f87-9ad8-7c9944982a4f"
      },
      "source": [
        "### **Resultados**\n",
        "\n",
        "#### **1. Clasificación Binaria (Dataset Breast Cancer)**\n",
        "\n",
        "- **Matriz de Confusión**:\n",
        "  - Verdaderos Positivos (TP): 70\n",
        "  - Verdaderos Negativos (TN): 40\n",
        "  - Falsos Positivos (FP): 3\n",
        "  - Falsos Negativos (FN): 1\n",
        "  - Esto muestra que el modelo tiene un excelente desempeño en la clasificación de tumores benignos y malignos.\n",
        "\n",
        "- **Curva ROC-AUC**:\n",
        "  - **AUC (Área bajo la curva):** 1.00\n",
        "  - Un AUC cercano a 1 indica un modelo casi perfecto para distinguir entre las clases (benigno/maligno).\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Regresión (Dataset Diabetes)**\n",
        "\n",
        "- **Gráfico de Predicción vs Valores Reales**:\n",
        "  - Los puntos representan las predicciones del modelo frente a los valores reales.\n",
        "  - La línea roja indica la línea ideal (\\(y = x\\)), donde las predicciones coinciden con los valores reales.\n",
        "  - Aunque el modelo sigue la tendencia general, existen errores significativos, especialmente en valores extremos.\n",
        "\n",
        "- **Métricas de Evaluación**:\n",
        "  - **Mean Squared Error (MSE):** 2900.19\n",
        "    - Error promedio al cuadrado entre las predicciones y los valores reales. Un valor más bajo es mejor.\n",
        "  - **R² Score:** 0.45\n",
        "    - El modelo explica el 45% de la variabilidad en los datos. Un valor más cercano a 1 sería ideal.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusión**\n",
        "\n",
        "- **Clasificación (Breast Cancer):** El modelo Random Forest tiene un desempeño excelente con métricas sólidas como una matriz de confusión clara y un AUC de 1.00.\n",
        "- **Regresión (Diabetes):** El modelo Linear Regression capta parte de la relación entre las características y la progresión de la diabetes, pero su desempeño podría mejorarse utilizando modelos más complejos como Random Forest Regressor o ajustando hiperparámetros."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6063335f-53bb-4a2d-a70d-0912329b48c3",
      "metadata": {
        "id": "6063335f-53bb-4a2d-a70d-0912329b48c3",
        "lines_to_next_cell": 0
      },
      "source": [
        "## 7. Partición del Dataset\n",
        "\n",
        "La partición del dataset en entrenamiento y validación es crucial para evitar sobreajuste.\n",
        "\n",
        "### Código básico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd216ac4",
      "metadata": {
        "id": "cd216ac4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71c27e15-ab7c-483b-9491-c97967ee65a3",
      "metadata": {
        "id": "71c27e15-ab7c-483b-9491-c97967ee65a3"
      },
      "source": [
        "## Algoritmos soportados en scikit-learn\n",
        "\n",
        "| Categoría                    | Algoritmo (Clase en sklearn)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
        "|------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Clasificación                | LogisticRegression, RidgeClassifier, Perceptron, PassiveAggressiveClassifier, SGDClassifier, KNeighborsClassifier, RadiusNeighborsClassifier, DecisionTreeClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier, GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB, SVC, NuSVC, LinearSVC, NearestCentroid, QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis, DummyClassifier |\n",
        "| Clustering                   | KMeans, MiniBatchKMeans, AgglomerativeClustering, Birch, DBSCAN, OPTICS, MeanShift, SpectralClustering, AffinityPropagation                                                                                                                                                                                                                                                                                                                                                                                    |\n",
        "| Reducción de dimensionalidad | PCA, IncrementalPCA, KernelPCA, SparsePCA, TruncatedSVD, FastICA, FactorAnalysis, NMF, DictionaryLearning, MiniBatchDictionaryLearning, LatentDirichletAllocation                                                                                                                                                                                                                                                                                                                                              |\n",
        "| Regresión                    | LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, ARDRegression, HuberRegressor, TheilSenRegressor, RANSACRegressor, SGDRegressor, KNeighborsRegressor, RadiusNeighborsRegressor, DecisionTreeRegressor, RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, BaggingRegressor, AdaBoostRegressor, DummyRegressor, PLSRegression, OrthogonalMatchingPursuit, Lars, LassoLars                                                                         |\n",
        "| Vecinos                      | NearestNeighbors, KNeighbors*, RadiusNeighbors*                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fbc6ab7",
      "metadata": {
        "id": "3fbc6ab7"
      },
      "source": [
        "---\n",
        "\n",
        "## Conclusión\n",
        "\n",
        "Este crash course proporciona una base sólida para comenzar a trabajar con Machine Learning utilizando Scikit-learn. ¡Explora los algoritmos y métricas para resolver tus problemas específicos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3563778c-c4cc-4ff3-b5de-60f1b1ef1a53",
      "metadata": {
        "id": "3563778c-c4cc-4ff3-b5de-60f1b1ef1a53"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}