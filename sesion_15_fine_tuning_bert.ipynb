{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubuntu/Taller_Introduccion_a_Ciencia_de_Datos_IA_e_Ingenieria_de_Datos/blob/main/sesion_15_fine_tuning_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "118efa3a",
      "metadata": {
        "id": "118efa3a"
      },
      "source": [
        "# üßë‚Äçüíª Sesi√≥n 15 ‚Äì Fine-tuning de BERT para An√°lisis de Sentimiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ac2693d",
      "metadata": {
        "id": "9ac2693d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ==========================================\n",
        "# SESI√ìN 15: Fine-tuning de BERT en IMDB\n",
        "# ==========================================\n",
        "\n",
        "#!pip install transformers datasets torch scikit-learn -q\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec9765cc",
      "metadata": {
        "id": "ec9765cc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Dataset IMDB (25k train / 25k test)\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Reducimos para entrenar r√°pido en clase\n",
        "small_train = dataset[\"train\"].shuffle(seed=42).select(range(2000))\n",
        "small_test = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e742aec9",
      "metadata": {
        "id": "e742aec9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Baseline cl√°sico ‚Äì TF-IDF + Logistic Regression\n",
        "X_train = small_train[\"text\"]\n",
        "y_train = small_train[\"label\"]\n",
        "X_test = small_test[\"text\"]\n",
        "y_test = small_test[\"label\"]\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Baseline TF-IDF + LogReg -> Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e9caf45",
      "metadata": {
        "id": "4e9caf45"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "train_enc = small_train.map(tokenize, batched=True, batch_size=32)\n",
        "test_enc = small_test.map(tokenize, batched=True, batch_size=32)\n",
        "\n",
        "train_enc.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_enc.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "394387a9",
      "metadata": {
        "id": "394387a9"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75808cf5",
      "metadata": {
        "id": "75808cf5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    num_train_epochs=2,  # demo r√°pida\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=20\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_enc,\n",
        "    eval_dataset=test_enc,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "978549d4",
      "metadata": {
        "id": "978549d4"
      },
      "outputs": [],
      "source": [
        "\n",
        "trainer.train()\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26c35888",
      "metadata": {
        "id": "26c35888"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"=== Comparaci√≥n final ===\")\n",
        "print(f\"Baseline TF-IDF + LogReg -> Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
        "print(f\"BERT Fine-tuned         -> Accuracy: {metrics['eval_accuracy']:.4f}, F1: {metrics['eval_f1']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7c8bcd6",
      "metadata": {
        "id": "c7c8bcd6"
      },
      "outputs": [],
      "source": [
        "\n",
        "examples = [\n",
        "    \"I really loved this movie, the story was amazing!\",\n",
        "    \"This was the worst customer experience I ever had.\"\n",
        "]\n",
        "\n",
        "inputs = tokenizer(examples, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "for txt, pred in zip(examples, preds):\n",
        "    label = \"positive\" if pred.item() == 1 else \"negative\"\n",
        "    print(f\"{txt} -> {label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0bae036",
      "metadata": {
        "id": "f0bae036"
      },
      "source": [
        "\n",
        "## Conclusi√≥n y discusi√≥n\n",
        "\n",
        "- **TF-IDF + LogReg**: r√°pido, interpretable, rendimiento aceptable (~80‚Äì85%).  \n",
        "- **BERT fine-tuned**: mayor performance (~90%+), pero con m√°s costo y menor interpretabilidad.  \n",
        "- En un empresa: trade-off entre **performance vs costo vs explicabilidad**.  \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}