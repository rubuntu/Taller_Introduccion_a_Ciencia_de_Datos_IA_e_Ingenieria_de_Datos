{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubuntu/Taller_Introduccion_a_Ciencia_de_Datos_IA_e_Ingenieria_de_Datos/blob/main/sesion_06_validacion_y_modelos_clasicos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5d6654b",
      "metadata": {
        "id": "c5d6654b"
      },
      "source": [
        "# Sesion 06 — Validación y Modelos Clásicos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71182087",
      "metadata": {
        "id": "71182087"
      },
      "source": [
        "# Parte A - Validación cruzada y métricas de performance\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48635d6f-74ec-41ef-9dca-4ade9e466f30",
      "metadata": {
        "id": "48635d6f-74ec-41ef-9dca-4ade9e466f30"
      },
      "source": [
        "## Objetivos\n",
        "- Entender la importancia de la validación cruzada.\n",
        "- Conocer métricas comunes: Accuracy, Precision, Recall, F1, ROC-AUC.\n",
        "- Evaluar un modelo de churn de forma rigurosa.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Validación Cruzada\n",
        "Divide los datos en **k-folds**.  \n",
        "Cada fold se usa una vez para test y el resto para train.  \n",
        "Ventaja: evita depender de una sola partición.\n",
        "\n",
        "*Referencia:* https://www.datacamp.com/es/tutorial/k-fold-cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c756668-622e-442f-98fd-49dcbf7f9cfd",
      "metadata": {
        "id": "8c756668-622e-442f-98fd-49dcbf7f9cfd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import numpy as np\n",
        "\n",
        "# Parámetros\n",
        "n_samples = 25\n",
        "n_splits = 5\n",
        "indices = np.arange(n_samples)\n",
        "\n",
        "# Colores para las 5 carpetas\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, n_splits))\n",
        "\n",
        "# Crear figura\n",
        "fig, ax = plt.subplots(figsize=(10, 2))\n",
        "bars = ax.bar(indices, np.ones_like(indices), color=\"lightgray\", edgecolor=\"black\")\n",
        "\n",
        "ax.set_xticks(indices)\n",
        "ax.set_yticks([])\n",
        "ax.set_title(\"Validación Cruzada de 5 Carpetas\", fontsize=14)\n",
        "ax.set_xlabel(\"Observaciones\")\n",
        "\n",
        "def update(frame):\n",
        "    for bar in bars:\n",
        "        bar.set_color(\"lightgray\")\n",
        "    test_idx = np.array_split(indices, n_splits)[frame]\n",
        "    for i in range(len(indices)):\n",
        "        if i in test_idx:\n",
        "            bars[i].set_color(colors[frame])  # Test set\n",
        "        else:\n",
        "            bars[i].set_color(\"lightblue\")   # Train set\n",
        "    ax.set_title(f\"Validación Cruzada - Fold {frame+1}\", fontsize=14)\n",
        "    return bars\n",
        "\n",
        "ani = animation.FuncAnimation(fig, update, frames=n_splits, blit=False, repeat=True)\n",
        "\n",
        "# Guardar como GIF sin mostrar\n",
        "gif_path = \"cross_validation_5fold.gif\"\n",
        "ani.save(gif_path, writer=\"pillow\", fps=1)\n",
        "plt.close(fig)  # Cierra la figura para que no se renderice en Jupyter\n",
        "\n",
        "#print(f\"Animación guardada en: {gif_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b670656f-4a94-43e8-ad5c-82f88baa9053",
      "metadata": {
        "id": "b670656f-4a94-43e8-ad5c-82f88baa9053"
      },
      "source": [
        "![Animación de Validación Cruzada](cross_validation_5fold.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "111f4368-d179-43a6-bc29-bdb10b343f38",
      "metadata": {
        "id": "111f4368-d179-43a6-bc29-bdb10b343f38"
      },
      "source": [
        "## 2. Ejemplo con Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01c78219",
      "metadata": {
        "id": "01c78219"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. Cargar dataset\n",
        "url = \"https://raw.githubusercontent.com/Geo-y20/Telco-Customer-Churn-/refs/heads/main/Telco%20Customer%20Churn.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "df[\"TotalCharges\"] = df[\"TotalCharges\"].fillna(df[\"MonthlyCharges\"])\n",
        "display(df.head())\n",
        "\n",
        "# 2. Eliminar columnas irrelevantes\n",
        "df = df.drop(\"customerID\", axis=1)\n",
        "\n",
        "# 3. One-Hot Encoding con pandas para variables categóricas\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# 4. Separar variables y target (Definir X e y)\n",
        "X = df.drop(\"Churn_Yes\", axis=1)  # porque get_dummies crea Churn_No y Churn_Yes\n",
        "y = df[\"Churn_Yes\"]\n",
        "\n",
        "# 5. Escalar datos\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# 6. Definir modelo\n",
        "clf = LogisticRegression(max_iter=5000)\n",
        "\n",
        "# 7. Validación cruzada\n",
        "scores = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
        "print(\"Accuracy promedio:\", np.mean(scores))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f73d5182",
      "metadata": {
        "id": "f73d5182"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Métricas de Clasificación\n",
        "\n",
        "* **Accuracy**: % de predicciones correctas.\n",
        "* **Precision**: proporción de positivos predichos que son correctos.\n",
        "* **Recall**: proporción de verdaderos positivos detectados.\n",
        "* **F1**: balance entre precision y recall.\n",
        "* **ROC-AUC**: mide discriminación entre clases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01d622c7",
      "metadata": {
        "id": "01d622c7"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. Curva ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e6696d9",
      "metadata": {
        "id": "1e6696d9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d380a2-40f4-4a8f-bd2f-1bbc7b876624",
      "metadata": {
        "id": "d5d380a2-40f4-4a8f-bd2f-1bbc7b876624"
      },
      "source": [
        "---\n",
        "\n",
        "## 5. Ejercicio Guiado\n",
        "\n",
        "1. Aplicar validación cruzada al modelo de churn.\n",
        "2. Calcular precision, recall y f1-score.\n",
        "3. Graficar la curva ROC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970e8fae-6a8b-4668-8bc9-9c86213b6e01",
      "metadata": {
        "id": "970e8fae-6a8b-4668-8bc9-9c86213b6e01"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "# 1) Cargar dataset\n",
        "url = \"https://raw.githubusercontent.com/Geo-y20/Telco-Customer-Churn-/refs/heads/main/Telco%20Customer%20Churn.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Limpieza mínima recomendada por este dataset\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "df[\"TotalCharges\"] = df[\"TotalCharges\"].fillna(df[\"MonthlyCharges\"])\n",
        "\n",
        "# 2) Eliminar columnas irrelevantes\n",
        "df = df.drop(columns=[\"customerID\"])\n",
        "\n",
        "# 3) One-Hot Encoding\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# 4) X, y\n",
        "X = df.drop(columns=[\"Churn_Yes\"])\n",
        "y = df[\"Churn_Yes\"]\n",
        "\n",
        "# 5) Modelo en Pipeline para evitar fuga de información del escalado\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"clf\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# 6) Definir validación cruzada y métricas\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = {\n",
        "    \"accuracy\": \"accuracy\",\n",
        "    \"precision\": \"precision\",\n",
        "    \"recall\": \"recall\",\n",
        "    \"f1\": \"f1\",\n",
        "    \"roc_auc\": \"roc_auc\"\n",
        "}\n",
        "\n",
        "# 7) cross_validate para obtener métricas por fold y promedio\n",
        "cv_results = cross_validate(pipe, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
        "\n",
        "print(\"=== Métricas promedio (5-fold CV) ===\")\n",
        "for m in scoring.keys():\n",
        "    vals = cv_results[f\"test_{m}\"]\n",
        "    print(f\"{m.capitalize():<9}: {vals.mean():.4f}  (± {vals.std():.4f})\")\n",
        "\n",
        "# 8) Predicciones out-of-fold para reportes agregados (confusion matrix, ROC, etc.)\n",
        "#    cross_val_predict entrena en cada fold y predice sobre el holdout de ese fold.\n",
        "y_pred_oof = cross_val_predict(pipe, X, y, cv=cv, method=\"predict\")\n",
        "y_prob_oof = cross_val_predict(pipe, X, y, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "\n",
        "# 9) Reportes agregados con OOF\n",
        "print(\"\\n=== Reporte de clasificación (OOF) ===\")\n",
        "print(classification_report(y, y_pred_oof, digits=4))\n",
        "\n",
        "cm = confusion_matrix(y, y_pred_oof)\n",
        "print(\"=== Matriz de confusión (OOF) ===\")\n",
        "print(cm)\n",
        "\n",
        "acc  = accuracy_score(y, y_pred_oof)\n",
        "prec = precision_score(y, y_pred_oof)\n",
        "rec  = recall_score(y, y_pred_oof)\n",
        "f1   = f1_score(y, y_pred_oof)\n",
        "rocA = roc_auc_score(y, y_prob_oof)\n",
        "\n",
        "print(\"\\n=== Métricas agregadas (OOF) ===\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall   : {rec:.4f}\")\n",
        "print(f\"F1       : {f1:.4f}\")\n",
        "print(f\"ROC-AUC  : {rocA:.4f}\")\n",
        "\n",
        "# 10) Curva ROC (OOF)\n",
        "fpr, tpr, _ = roc_curve(y, y_prob_oof)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {rocA:.3f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Azar\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Curva ROC (validación cruzada OOF)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7131df26-adec-43c7-99e6-248433a92613",
      "metadata": {
        "id": "7131df26-adec-43c7-99e6-248433a92613"
      },
      "source": [
        "---\n",
        "\n",
        "## 6. Preguntas de Discusión\n",
        "\n",
        "### 6.1. ¿Por qué conviene usar validación cruzada?\n",
        "\n",
        "* **Idea central:** La validación cruzada permite evaluar el desempeño de un modelo no en un único “corte” de train/test, sino en múltiples particiones.\n",
        "* **Beneficio:**\n",
        "\n",
        "  * Reduce la **varianza** en la estimación del desempeño.\n",
        "  * Asegura que todos los datos participan alguna vez como entrenamiento y como validación.\n",
        "  * Evita que nuestra evaluación dependa de un “golpe de suerte” en cómo partimos los datos.\n",
        "* **Analogía:** Es como probar un coche no solo en una pista lisa, sino también en caminos distintos para asegurarnos de que rinde bien en general.\n",
        "\n",
        "---\n",
        "\n",
        "### 6.2. ¿Qué métrica elegir si me importa más detectar todos los clientes que van a fugarse (churn)?\n",
        "\n",
        "* Aquí hablamos de **sensibilidad/recall**.\n",
        "* **Recall** = de todos los que realmente se fueron, ¿cuántos detecté?\n",
        "* Si tu objetivo es **no perder a ningún cliente que se fuga**, necesitas maximizar el recall, incluso si eso significa aceptar más falsos positivos.\n",
        "* **Ejemplo:** Es como un detector de incendios: mejor que suene muchas veces aunque sea por vapor de la ducha, a que no suene cuando hay fuego real.\n",
        "\n",
        "---\n",
        "\n",
        "### 6.3. ¿Y si el costo de un falso positivo es muy alto?\n",
        "\n",
        "* Entonces priorizamos la **precisión**.\n",
        "* **Precisión** = de todos los que marqué como fuga, ¿cuántos realmente se fueron?\n",
        "* Si contactar o dar beneficios a un cliente mal clasificado cuesta mucho, entonces conviene sacrificar recall y ganar en precisión.\n",
        "* **Ejemplo:** Campañas de retención costosas: no quieres gastar en clientes que igual no se iban a ir.\n",
        "\n",
        "---\n",
        "\n",
        "### 6.4. ¿Por qué ROC-AUC es preferible a Accuracy en problemas desbalanceados?\n",
        "\n",
        "* En datasets desbalanceados, la **accuracy** puede ser engañosa:\n",
        "\n",
        "  * Si el 95% de clientes no se fuga, un modelo que siempre prediga “no fuga” tendrá 95% de accuracy.\n",
        "  * Pero ese modelo no sirve para detectar churn.\n",
        "* **ROC-AUC** mide la capacidad del modelo de rankear correctamente entre positivos y negativos.\n",
        "\n",
        "  * Es independiente del umbral de decisión.\n",
        "  * Permite comparar modelos incluso en situaciones de gran desbalance.\n",
        "* **Ejemplo:** En un aeropuerto, casi todos los equipajes son normales; accuracy te diría “estás perfecto” si nunca detectas nada sospechoso. Pero lo que interesa es tu habilidad de distinguir maletas peligrosas de las normales.\n",
        "\n",
        "### 6.5. ¿Qué trade-off aceptarías en un banco? ¿Y en un hospital?\n",
        "\n",
        "| Contexto                   | Costo más grave                                | Métrica a priorizar           | Ejemplo de decisión                                                                 |\n",
        "| -------------------------- | ---------------------------------------------- | ----------------------------- | ----------------------------------------------------------------------------------- |\n",
        "| **Banco – Churn**          | Falso negativo (perder un cliente que se fuga) | Recall (Sensibilidad)         | Mejor contactar de más que perder clientes valiosos                                 |\n",
        "| **Banco – Fraude**         | Falso positivo (bloquear cliente inocente)     | Precisión                     | Minimizar molestias y costos reputacionales                                         |\n",
        "| **Banco – Scoring (tradicional)** | Falso positivo (dar crédito a quien no paga)   | Precisión en clase “aprobado” | Mejor rechazar a algunos buenos que aprobar demasiados malos                        |\n",
        "| **Banco – Scoring (inclusión/fintech)** | Falso negativo (rechazar a un cliente confiable) | Recall (Sensibilidad)         | Mejor aceptar a casi todos los buenos clientes aunque se filtren algunos malos      |\n",
        "| **Hospital – Diagnóstico** | Falso negativo (no detectar enfermo)           | Recall (Sensibilidad)         | Mejor hacer pruebas extras que dejar un enfermo sin diagnóstico                     |\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5334fa80",
      "metadata": {
        "id": "5334fa80"
      },
      "source": [
        "# Parte B: Modelos clásicos (Logistic Regression y Árboles)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "734272e5",
      "metadata": {
        "id": "734272e5"
      },
      "source": [
        "## Objetivos\n",
        "- Aplicar Logistic Regression a un caso real de churn.\n",
        "- Comparar con un Árbol de Decisión.\n",
        "- Analizar ventajas/desventajas de cada modelo.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Dataset Churn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb64cecf",
      "metadata": {
        "id": "eb64cecf"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d27d7b46",
      "metadata": {
        "id": "d27d7b46"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "lr = LogisticRegression(max_iter=5000)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "y_proba_lr = lr.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_proba_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8bd7234",
      "metadata": {
        "id": "b8bd7234"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Árbol de Decisión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa380a93",
      "metadata": {
        "id": "aa380a93"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_tree = tree.predict(X_test)\n",
        "y_proba_tree = tree.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"Decision Tree\")\n",
        "print(classification_report(y_test, y_pred_tree))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_proba_tree))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f95e836-25d3-429e-97be-26c3027488f3",
      "metadata": {
        "id": "5f95e836-25d3-429e-97be-26c3027488f3"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0879cf51-d9eb-4f32-adfd-ad48ccaf5051",
      "metadata": {
        "id": "0879cf51-d9eb-4f32-adfd-ad48ccaf5051"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Definir modelo Random Forest\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,   # número de árboles\n",
        "    max_depth=6,        # profundidad máxima de cada árbol\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Entrenar\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Métricas\n",
        "print(\"Random Forest\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_proba_rf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b24bdae-49cb-4f2a-bfb8-6d0d108e8e1f",
      "metadata": {
        "id": "3b24bdae-49cb-4f2a-bfb8-6d0d108e8e1f"
      },
      "source": [
        "---\n",
        "\n",
        "🔎 **Diferencias clave RandomForestClassifier vs DecisionTreeClassifier**:\n",
        "\n",
        "* `RandomForestClassifier` combina muchos árboles (bagging) → más robusto y menos sobreajuste.\n",
        "* Hiperparámetros importantes:\n",
        "\n",
        "  * `n_estimators`: nº de árboles (100–500 es común).\n",
        "  * `max_depth`: controla complejidad (igual que en árboles individuales).\n",
        "  * `max_features`: nº de variables usadas en cada split (default = sqrt para clasificación).\n",
        "* Se obtiene `predict` y `predict_proba` igual que en el árbol simple.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46e324cb",
      "metadata": {
        "id": "46e324cb"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. Comparación Gráfica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe4bce4a",
      "metadata": {
        "id": "fe4bce4a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import RocCurveDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "RocCurveDisplay.from_estimator(lr, X_test, y_test, name=\"Logistic Regression\")\n",
        "RocCurveDisplay.from_estimator(tree, X_test, y_test, name=\"Decision Tree\")\n",
        "RocCurveDisplay.from_estimator(rf, X_test, y_test, name=\"Random Forest\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8999a06f",
      "metadata": {
        "id": "8999a06f"
      },
      "source": [
        "---\n",
        "\n",
        "## 5. Discusión\n",
        "\n",
        "* **Logistic Regression**:\n",
        "\n",
        "  * Modelo lineal, interpretable.\n",
        "  * Útil como *baseline* porque establece un punto de referencia claro.\n",
        "  * Bueno cuando las relaciones entre variables y el objetivo son aproximadamente lineales.\n",
        "  * Fácil de explicar a negocio (“cada variable aumenta/disminuye la probabilidad de churn en tanto %”).\n",
        "\n",
        "* **Decision Tree**:\n",
        "\n",
        "  * Captura relaciones **no lineales** y **interacciones** entre variables sin necesidad de transformaciones.\n",
        "  * Fácil de explicar visualmente (se puede graficar el árbol y mostrar las reglas).\n",
        "  * Puede sobreajustar si no se controla la profundidad u otros parámetros.\n",
        "  * Bueno para comunicación, pero menos estable (pequeños cambios en los datos → árbol diferente).\n",
        "\n",
        "* **Random Forest**:\n",
        "\n",
        "  * Conjunto de muchos árboles → más robusto y con mejor desempeño promedio que un solo árbol.\n",
        "  * Reduce el riesgo de sobreajuste combinando resultados (bagging).\n",
        "  * Captura no linealidades y complejas interacciones de forma más estable.\n",
        "  * Menos interpretable que un árbol único o regresión logística (aunque se pueden usar **importancias de variables** o **SHAP** para interpretarlo).\n",
        "  * Normalmente alcanza un **mejor equilibrio entre bias y varianza**.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Preguntas de Discusión\n",
        "\n",
        "1. ¿Qué modelo recomendarían para presentar a un equipo de negocio?\n",
        "2. ¿Qué riesgos hay de sobreajuste en un árbol?\n",
        "3. ¿Cómo se podrían combinar ambos enfoques?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7802ab3-aa06-44bb-a73e-664296d43039",
      "metadata": {
        "id": "d7802ab3-aa06-44bb-a73e-664296d43039"
      },
      "source": [
        "## 6. Preguntas de Discusión\n",
        "\n",
        "**1. ¿Qué modelo recomendarían para presentar a un equipo de negocio?**\n",
        "\n",
        "* **Regresión Logística** es normalmente la opción más adecuada para presentaciones a negocio porque:\n",
        "\n",
        "  * Es **fácil de interpretar**: cada variable tiene un coeficiente que indica su impacto en la probabilidad de churn.\n",
        "  * Permite explicar “qué factores incrementan la probabilidad de fuga”.\n",
        "  * Ideal como **baseline** antes de pasar a modelos más complejos.\n",
        "* **Árbol de Decisión** también es una buena alternativa si se quiere mostrar reglas claras y visuales (“si el cliente tiene contrato mensual y bajo tenure → alta probabilidad de churn”).\n",
        "\n",
        "---\n",
        "\n",
        "**2. ¿Qué riesgos hay de sobreajuste en un árbol?**\n",
        "\n",
        "* Un **árbol profundo** puede aprender demasiado los datos de entrenamiento, detectando patrones espurios.\n",
        "* Esto se traduce en **alta accuracy en train pero bajo desempeño en test**.\n",
        "* Factores de riesgo:\n",
        "\n",
        "  * No limitar la profundidad (`max_depth`).\n",
        "  * No restringir el número mínimo de muestras por hoja (`min_samples_leaf`).\n",
        "  * Dataset con ruido o muchas variables categóricas.\n",
        "\n",
        "---\n",
        "\n",
        "**3. ¿Cómo se podrían combinar ambos enfoques?**\n",
        "\n",
        "* **Random Forest** es justamente la combinación de muchos árboles (bagging), reduciendo la varianza y mejorando la generalización.\n",
        "* Otra alternativa es **Ensemble Híbrido**:\n",
        "\n",
        "  * Usar **Regresión Logística** como baseline por su interpretabilidad.\n",
        "  * Usar **Random Forest / Gradient Boosting** para mejorar predicciones.\n",
        "  * Comparar ambos y reportar al negocio insights del modelo interpretable + performance del modelo robusto.\n",
        "* Incluso se pueden usar **modelos en cascada**: primero un modelo interpretable para filtrar casos “claros” y luego un modelo complejo para los “dudosos”.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}