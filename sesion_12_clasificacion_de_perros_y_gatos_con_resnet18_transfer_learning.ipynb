{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubuntu/Taller_Introduccion_a_Ciencia_de_Datos_IA_e_Ingenieria_de_Datos/blob/main/sesion_12_clasificacion_de_perros_y_gatos_con_resnet18_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "551d7429-cd9d-4dfd-b6cd-0901ff6d6034",
      "metadata": {
        "id": "551d7429-cd9d-4dfd-b6cd-0901ff6d6034"
      },
      "source": [
        "# Clasificaci√≥n de Perros y Gatos con ResNet18 (Transfer Learning)\n",
        "\n",
        "## Objetivos\n",
        "- Aprender a cargar datasets de im√°genes desde HuggingFace (`microsoft/cats_vs_dogs`).\n",
        "- Preparar un pipeline de preprocesamiento con **transformaciones y data augmentation**.\n",
        "- Usar un modelo preentrenado (**ResNet18 con pesos de ImageNet**) y adaptarlo al problema de clasificaci√≥n binaria.\n",
        "- Practicar el concepto de **congelar capas y entrenar solo las √∫ltimas** (fine-tuning parcial).\n",
        "- Implementar **entrenamiento con early stopping** para evitar overfitting.\n",
        "- Evaluar el modelo y visualizar ejemplos de predicciones correctas e incorrectas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e050f27",
      "metadata": {
        "id": "1e050f27"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from datasets import load_dataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Usando dispositivo:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6563df3c-c812-4620-be8d-5bf2cb22eda9",
      "metadata": {
        "id": "6563df3c-c812-4620-be8d-5bf2cb22eda9"
      },
      "source": [
        "## 1. Cargar dataset p√∫blico (HuggingFace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef9c4b9d",
      "metadata": {
        "id": "ef9c4b9d"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"microsoft/cats_vs_dogs\")\n",
        "\n",
        "# Dividir en 80% train / 20% test\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.2)\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "380ee705-d109-4455-bf14-3e30f9c7c207",
      "metadata": {
        "id": "380ee705-d109-4455-bf14-3e30f9c7c207"
      },
      "source": [
        "## 2. Transformaciones (Data Augmentation + Normalizaci√≥n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88550b37",
      "metadata": {
        "id": "88550b37"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),  # ‚ö†Ô∏è convertir a RGB\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.Lambda(lambda img: img.convert(\"RGB\")),  # ‚ö†Ô∏è convertir a RGB\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69ae6d3d-313b-4b5e-a118-a17118683924",
      "metadata": {
        "id": "69ae6d3d-313b-4b5e-a118-a17118683924"
      },
      "source": [
        "## 3. Adaptador HuggingFace ‚Üí PyTorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d94dda79",
      "metadata": {
        "id": "d94dda79"
      },
      "outputs": [],
      "source": [
        "class CatsDogsDataset(Dataset):\n",
        "    def __init__(self, hf_dataset, transform=None):\n",
        "        self.data = hf_dataset\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.data[idx][\"image\"]\n",
        "        label = self.data[idx][\"labels\"]   # ‚ö†Ô∏è usar 'labels' en lugar de 'file'\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "train_ds = CatsDogsDataset(dataset[\"train\"], transform=transform_train)\n",
        "test_ds  = CatsDogsDataset(dataset[\"test\"], transform=transform_test)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "test_dl  = DataLoader(test_ds, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "397a8f6c-51c5-41fa-bc6a-e176b31c532a",
      "metadata": {
        "id": "397a8f6c-51c5-41fa-bc6a-e176b31c532a"
      },
      "source": [
        "## 4. Definir modelo (ResNet18 con pesos de ImageNet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b60ae03a",
      "metadata": {
        "id": "b60ae03a"
      },
      "outputs": [],
      "source": [
        "weights = ResNet18_Weights.DEFAULT\n",
        "model = resnet18(weights=weights)\n",
        "\n",
        "# Congelar todas las capas excepto las √∫ltimas\n",
        "for name, param in model.named_parameters():\n",
        "    if \"layer4\" in name or \"fc\" in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Reemplazar la √∫ltima capa para 2 clases\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a75ff83-15db-4655-a49d-c8029b273596",
      "metadata": {
        "id": "3a75ff83-15db-4655-a49d-c8029b273596"
      },
      "source": [
        "## 5. Entrenamiento con Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f424041",
      "metadata": {
        "id": "1f424041"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
        "\n",
        "#n_epochs = 20\n",
        "n_epochs = 1\n",
        "patience = 3\n",
        "best_acc = 0\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # --- Entrenamiento ---\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for xb, yb in train_dl:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        preds = model(xb)\n",
        "        loss = loss_fn(preds, yb)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # --- Evaluaci√≥n ---\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            preds = model(xb).argmax(dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += yb.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    print(f\"Epoch {epoch+1}, Loss={running_loss/len(train_dl):.4f}, Val Acc={acc:.4f}\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), \"best_catsdogs.pth\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(\"Early stopping activado\")\n",
        "            break\n",
        "\n",
        "print(\"Mejor accuracy alcanzado:\", best_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "976150ca-d43c-4ab3-855c-6c5a3d7f60f2",
      "metadata": {
        "id": "976150ca-d43c-4ab3-855c-6c5a3d7f60f2"
      },
      "source": [
        "## 6. Visualizaci√≥n de predicciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f111fb5b",
      "metadata": {
        "id": "f111fb5b"
      },
      "outputs": [],
      "source": [
        "\n",
        "images, labels = next(iter(test_dl))\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "preds = model(images).argmax(dim=1)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "for i in range(8):\n",
        "    plt.subplot(2,4,i+1)\n",
        "    img = images[i].cpu().permute(1,2,0).numpy()\n",
        "    img = (img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]).clip(0,1)  # desnormalizar\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Real: {labels[i].item()}, Pred: {preds[i].item()}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9601a9fa-6b6c-4041-b19a-835784b3abbf",
      "metadata": {
        "id": "9601a9fa-6b6c-4041-b19a-835784b3abbf"
      },
      "source": [
        "## Preguntas de Discusi√≥n\n",
        "\n",
        "1. ¬øQu√© ventajas ofrece usar un modelo preentrenado (transfer learning) frente a entrenar desde cero?\n",
        "2. ¬øPor qu√© es √∫til congelar capas en el inicio del entrenamiento y ajustar solo la √∫ltima capa?\n",
        "3. ¬øC√≥mo ayuda el *data augmentation* a mejorar la capacidad de generalizaci√≥n del modelo?\n",
        "4. ¬øQu√© diferencias observas en el rendimiento al descongelar m√°s capas para el fine-tuning?\n",
        "5. ¬øQu√© rol cumple la normalizaci√≥n con los valores de ImageNet en la estabilidad del entrenamiento?\n",
        "6. ¬øC√≥mo decide el early stopping cu√°ndo detener el entrenamiento y por qu√© es importante?\n",
        "7. ¬øQu√© m√©tricas adicionales (adem√°s de accuracy) podr√≠an ser √∫tiles en este problema?\n",
        "8. ¬øC√≥mo se podr√≠a mejorar a√∫n m√°s el modelo si se dispusiera de m√°s recursos computacionales?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üí° Preguntas de Discusi√≥n (desarrolladas)\n",
        "\n",
        "1. **¬øQu√© ventajas ofrece usar un modelo preentrenado (transfer learning) frente a entrenar desde cero?**\n",
        "\n",
        "   * Entrenar desde cero requiere grandes cantidades de datos y mucho tiempo de c√≥mputo.\n",
        "   * Los modelos preentrenados en ImageNet ya han aprendido caracter√≠sticas generales (bordes, texturas, formas), que son √∫tiles para muchos problemas de visi√≥n.\n",
        "   * Con *transfer learning*, solo se adapta la parte final de la red al nuevo conjunto de clases, logrando **mejor rendimiento con menos datos y menos tiempo de entrenamiento**.\n",
        "\n",
        "---\n",
        "\n",
        "2. **¬øPor qu√© es √∫til congelar capas en el inicio del entrenamiento y ajustar solo la √∫ltima capa?**\n",
        "\n",
        "   * Las primeras capas de una CNN aprenden caracter√≠sticas muy generales (l√≠neas, bordes, patrones de color).\n",
        "   * Si se ajustan todas desde el inicio, se corre el riesgo de *desaprender* esas representaciones √∫tiles.\n",
        "   * Congelarlas permite entrenar m√°s r√°pido y reducir el riesgo de sobreajuste, enfocando el aprendizaje solo en la capa de clasificaci√≥n final.\n",
        "\n",
        "---\n",
        "\n",
        "3. **¬øC√≥mo ayuda el *data augmentation* a mejorar la capacidad de generalizaci√≥n del modelo?**\n",
        "\n",
        "   * Genera versiones modificadas de las im√°genes (rotadas, espejadas, con variaciones de color).\n",
        "   * Esto obliga al modelo a aprender **patrones invariantes** a peque√±as transformaciones, en lugar de memorizar ejemplos concretos.\n",
        "   * Mejora la robustez y reduce el riesgo de sobreajuste cuando los datasets son peque√±os.\n",
        "\n",
        "---\n",
        "\n",
        "4. **¬øQu√© diferencias observas en el rendimiento al descongelar m√°s capas para el fine-tuning?**\n",
        "\n",
        "   * Congelar casi todo ‚Üí entrenamiento r√°pido pero menos capacidad de adaptaci√≥n al nuevo dominio.\n",
        "   * Descongelar √∫ltimas capas ‚Üí mejor ajuste al dataset objetivo, a costa de m√°s tiempo de entrenamiento.\n",
        "   * Descongelar toda la red ‚Üí mayor capacidad de adaptaci√≥n, pero mayor riesgo de sobreajuste si el dataset es peque√±o.\n",
        "   * En la pr√°ctica, **descongelar gradualmente** (empezando desde las √∫ltimas capas) suele dar los mejores resultados.\n",
        "\n",
        "---\n",
        "\n",
        "5. **¬øQu√© rol cumple la normalizaci√≥n con los valores de ImageNet en la estabilidad del entrenamiento?**\n",
        "\n",
        "   * Los modelos preentrenados esperan entradas con la misma estad√≠stica que los datos de ImageNet.\n",
        "   * Normalizar con `mean=[0.485, 0.456, 0.406]` y `std=[0.229, 0.224, 0.225]` alinea la distribuci√≥n de p√≠xeles con la que el modelo fue entrenado originalmente.\n",
        "   * Esto evita desajustes que podr√≠an degradar el rendimiento o dificultar la convergencia.\n",
        "\n",
        "---\n",
        "\n",
        "6. **¬øC√≥mo decide el early stopping cu√°ndo detener el entrenamiento y por qu√© es importante?**\n",
        "\n",
        "   * Early stopping monitorea una m√©trica de validaci√≥n (ej. p√©rdida o accuracy).\n",
        "   * Si no mejora despu√©s de un n√∫mero definido de √©pocas (*patience*), se detiene el entrenamiento.\n",
        "   * Esto evita que el modelo siga ajust√°ndose al conjunto de entrenamiento mientras empeora en el de validaci√≥n (sobreajuste).\n",
        "   * Tambi√©n ahorra tiempo y recursos.\n",
        "\n",
        "---\n",
        "\n",
        "7. **¬øQu√© m√©tricas adicionales (adem√°s de accuracy) podr√≠an ser √∫tiles en este problema?**\n",
        "\n",
        "   * **Precisi√≥n (precision):** proporci√≥n de predicciones positivas correctas (√∫til si queremos pocas falsas alarmas).\n",
        "   * **Recall (sensibilidad):** proporci√≥n de verdaderos positivos detectados (√∫til si no queremos dejar escapar casos).\n",
        "   * **F1-score:** balance entre precisi√≥n y recall.\n",
        "   * **Matriz de confusi√≥n:** para ver qu√© clases se confunden m√°s.\n",
        "   * **AUC-ROC:** mide la capacidad de distinguir entre clases en distintos umbrales.\n",
        "\n",
        "---\n",
        "\n",
        "8. **¬øC√≥mo se podr√≠a mejorar a√∫n m√°s el modelo si se dispusiera de m√°s recursos computacionales?**\n",
        "\n",
        "   * Usar arquitecturas m√°s grandes y potentes (**ResNet50, EfficientNet, Vision Transformers**).\n",
        "   * Entrenar durante m√°s √©pocas con estrategias de regularizaci√≥n (dropout, weight decay).\n",
        "   * Aumentar la resoluci√≥n de entrada (224√ó224 ‚Üí 384√ó384).\n",
        "   * Usar *ensembles* de varios modelos para combinar predicciones.\n",
        "   * Aplicar *semi-supervised learning* o *self-supervised pretraining* para aprovechar datos no etiquetados.\n",
        "\n"
      ],
      "metadata": {
        "id": "BMrEh9c-WIpf"
      },
      "id": "BMrEh9c-WIpf"
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "markdown",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}