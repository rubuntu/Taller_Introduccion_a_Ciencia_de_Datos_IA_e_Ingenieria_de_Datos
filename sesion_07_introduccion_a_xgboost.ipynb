{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubuntu/Taller_Introduccion_a_Ciencia_de_Datos_IA_e_Ingenieria_de_Datos/blob/main/sesion_07_introduccion_a_xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6820aa9d",
      "metadata": {
        "id": "6820aa9d"
      },
      "source": [
        "# Sesi√≥n 07: Introducci√≥n a XGBoost\n",
        "\n",
        "## Objetivos\n",
        "- Comprender qu√© es XGBoost y por qu√© es potente en clasificaci√≥n tabular.\n",
        "- Preparar el dataset de default de tarjetas de cr√©dito.\n",
        "- Entrenar un primer modelo de XGBoost y evaluarlo.\n",
        "\n",
        "---\n",
        "\n",
        "## üå≥ √Årboles de decisi√≥n\n",
        "\n",
        "Un **√°rbol de decisi√≥n** es un modelo de machine learning que divide los datos en ramas y hojas para hacer predicciones.\n",
        "\n",
        "* Se construye haciendo **preguntas secuenciales** sobre las variables (features).\n",
        "* Cada nodo interno representa una condici√≥n (ej. *‚Äú¬øedad < 30?‚Äù*).\n",
        "* Cada rama representa una respuesta (*s√≠ / no*).\n",
        "* Cada hoja contiene un resultado (predicci√≥n de clase o valor).\n",
        "\n",
        "üìå **Ventajas**\n",
        "\n",
        "* F√°cil de interpretar y visualizar.\n",
        "* Maneja variables num√©ricas y categ√≥ricas.\n",
        "* No requiere mucha preparaci√≥n de datos.\n",
        "\n",
        "üìå **Desventajas**\n",
        "\n",
        "* Puede sobreajustar (*overfitting*).\n",
        "* Sensibles a peque√±as variaciones en los datos.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö° Boosting\n",
        "\n",
        "El **boosting** es una t√©cnica de **ensemble learning** (modelos combinados) que mejora el rendimiento de modelos d√©biles (como √°rboles poco profundos).\n",
        "\n",
        "La idea principal es:\n",
        "\n",
        "1. Entrenar un **primer √°rbol**.\n",
        "2. Ver los **errores** que cometi√≥.\n",
        "3. Entrenar un **segundo √°rbol** que se enfoque en corregir esos errores.\n",
        "4. Repetir el proceso, combinando muchos √°rboles **d√©biles** para crear un **modelo fuerte**.\n",
        "\n",
        "### Ejemplos de algoritmos de boosting:\n",
        "\n",
        "* **AdaBoost**: ajusta pesos a las observaciones mal clasificadas.\n",
        "* **Gradient Boosting**: corrige errores minimizando una funci√≥n de p√©rdida (m√°s preciso que AdaBoost).\n",
        "* **XGBoost, LightGBM, CatBoost**: implementaciones modernas, r√°pidas y optimizadas de gradient boosting.\n",
        "\n",
        "üìå **Ventajas**\n",
        "\n",
        "* Suele lograr alta precisi√≥n.\n",
        "* Maneja relaciones no lineales y complejas.\n",
        "* Flexible (puede usarse para regresi√≥n y clasificaci√≥n).\n",
        "\n",
        "üìå **Desventajas**\n",
        "\n",
        "* M√°s dif√≠cil de interpretar que un solo √°rbol.\n",
        "* Computacionalmente m√°s costoso.\n",
        "* Puede sobreajustar si no se ajustan bien los hiperpar√°metros.\n",
        "\n",
        "---\n",
        "\n",
        "üëâ En pocas palabras:\n",
        "\n",
        "* **√Årbol de decisi√≥n** = un modelo sencillo y visual.\n",
        "* **Boosting** = muchos √°rboles peque√±os que se ayudan entre s√≠ corrigiendo errores.\n",
        "\n",
        "---\n",
        "## üîπ  ¬øQu√© es XGBoost?\n",
        "- **Extreme Gradient Boosting**: algoritmo basado en √°rboles de decisi√≥n y boosting.\n",
        "- Combina m√∫ltiples √°rboles d√©biles en un modelo fuerte.\n",
        "- Ventajas:\n",
        "  - Maneja bien datos tabulares.\n",
        "  - Regularizaci√≥n integrada (evita overfitting).\n",
        "  - Muy eficiente y escalable.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4973cf13-16a5-496c-a4c6-b3cecd0e1c0c",
      "metadata": {
        "id": "4973cf13-16a5-496c-a4c6-b3cecd0e1c0c"
      },
      "source": [
        "## üîπ ¬øQu√© son los SHAP Values?\n",
        "\n",
        "Los **SHAP Values** (**SHapley Additive exPlanations**) son una t√©cnica de **explicabilidad de modelos de machine learning**.\n",
        "Su objetivo es responder a la pregunta:\n",
        "\n",
        "üëâ *‚Äú¬øCu√°nto aporta cada variable (feature) a la predicci√≥n de un modelo para un caso espec√≠fico?‚Äù*\n",
        "\n",
        "Es decir, no solo dicen qu√© variables son importantes en general, sino tambi√©n **c√≥mo influyen en la predicci√≥n de cada individuo** (ejemplo: por qu√© el cliente 123 fue clasificado como riesgo alto).\n",
        "\n",
        "Cada predicci√≥n se descompone como:\n",
        "\n",
        "$$\n",
        "\\text{Predicci√≥n} = \\text{Valor base (esperado)} + \\sum_{i=1}^M \\text{SHAP value}_i\n",
        "$$\n",
        "\n",
        "* **Valor base**: la predicci√≥n promedio si no supi√©ramos nada (ej. probabilidad media de default en el dataset).\n",
        "* **SHAP value de una feature**: cu√°nto sube o baja la predicci√≥n al considerar esa variable en el caso concreto.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Origen: Teor√≠a de Juegos de Shapley (1953)\n",
        "\n",
        "Los SHAP Values se inspiran en los **valores de Shapley**, un concepto de la **teor√≠a de juegos cooperativos** de Lloyd Shapley (premio Nobel de Econom√≠a, 2012).\n",
        "\n",
        "En un juego cooperativo:\n",
        "\n",
        "* Hay **jugadores** que contribuyen a una recompensa com√∫n.\n",
        "* Los **valores de Shapley** determinan una forma justa de repartir la recompensa seg√∫n el aporte de cada jugador.\n",
        "\n",
        "En Machine Learning:\n",
        "\n",
        "* Los **jugadores** son las **variables (features)**.\n",
        "* La **recompensa** es la **predicci√≥n del modelo**.\n",
        "* El **valor de Shapley** indica cu√°nto contribuy√≥ cada variable a la predicci√≥n final.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Ventajas de SHAP\n",
        "\n",
        "* **Explicaciones consistentes y justas** (garantiza propiedades matem√°ticas de equidad heredadas de la teor√≠a de juegos).\n",
        "* **Explicaciones locales y globales**:\n",
        "\n",
        "  * Locales ‚Üí por instancia (ej. cliente espec√≠fico).\n",
        "  * Globales ‚Üí promedio de contribuciones, para ranking de importancia de variables.\n",
        "* **Aplicable a cualquier modelo** (√°rboles, redes neuronales, regresiones, etc.).\n",
        "* Tiene implementaciones optimizadas para modelos de √°rboles como **XGBoost, LightGBM, CatBoost**, lo que lo hace muy usado en datos tabulares.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ Resumen:\n",
        "Los **SHAP values** son una adaptaci√≥n de los **valores de Shapley (teor√≠a de juegos de 1953)** al mundo del machine learning. Nos permiten interpretar modelos complejos asignando a cada variable un aporte justo y cuantitativo en cada predicci√≥n.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89c5895f-8a78-4b81-859a-c12311c13db6",
      "metadata": {
        "id": "89c5895f-8a78-4b81-859a-c12311c13db6"
      },
      "source": [
        "## Dataset\n",
        "Fuente: [UCI Default of Credit Card Clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307dbc70-966e-4092-a7e0-5434e5224181",
      "metadata": {
        "id": "307dbc70-966e-4092-a7e0-5434e5224181"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c45963c9-5512-41b9-9d10-01b7fd232745",
      "metadata": {
        "id": "c45963c9-5512-41b9-9d10-01b7fd232745"
      },
      "outputs": [],
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "df = pd.read_excel(url, header=1)\n",
        "\n",
        "df.rename(columns={\"default payment next month\": \"default\"}, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e16c1634-ea78-47b1-999c-2cef6f88af2e",
      "metadata": {
        "id": "e16c1634-ea78-47b1-999c-2cef6f88af2e"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38880b93-ce78-4b8a-b9f0-6f01f13d29f5",
      "metadata": {
        "id": "38880b93-ce78-4b8a-b9f0-6f01f13d29f5"
      },
      "outputs": [],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c33b194f-394e-48f3-8209-d7737418fdec",
      "metadata": {
        "id": "c33b194f-394e-48f3-8209-d7737418fdec"
      },
      "outputs": [],
      "source": [
        "df.hist(bins=20, figsize=(10, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1ac96d7",
      "metadata": {
        "id": "d1ac96d7"
      },
      "source": [
        "---\n",
        "\n",
        "## Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29cae084",
      "metadata": {
        "id": "29cae084"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = df.drop(columns=[\"ID\",\"default\"])\n",
        "y = df[\"default\"]\n",
        "\n",
        "feature_names = list(X.columns)\n",
        "\n",
        "#scaler = StandardScaler()\n",
        "#X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d09a81fb-42a9-4517-983a-fb49379408c2",
      "metadata": {
        "id": "d09a81fb-42a9-4517-983a-fb49379408c2"
      },
      "outputs": [],
      "source": [
        "# X_scaled es un array de NumPy\n",
        "# stats = {\n",
        "#    \"count\": X_scaled.shape[0],\n",
        "#    \"mean\": np.mean(X_scaled, axis=0),\n",
        "#    \"std\": np.std(X_scaled, axis=0, ddof=1),  # ddof=1 para que sea como pandas\n",
        "#    \"min\": np.min(X_scaled, axis=0),\n",
        "#    \"25%\": np.percentile(X_scaled, 25, axis=0),\n",
        "#    \"50%\": np.median(X_scaled, axis=0),\n",
        "#    \"75%\": np.percentile(X_scaled, 75, axis=0),\n",
        "#    \"max\": np.max(X_scaled, axis=0)\n",
        "#}\n",
        "#pd.DataFrame(stats, index=X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fb7d268",
      "metadata": {
        "id": "9fb7d268"
      },
      "source": [
        "---\n",
        "\n",
        "## Entrenar XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bb2e6b6",
      "metadata": {
        "id": "5bb2e6b6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from xgboost import XGBClassifier, plot_importance, DMatrix\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "\n",
        "# Calcular el ratio\n",
        "neg, pos = np.bincount(y_train)\n",
        "scale = neg / pos\n",
        "print(f\"Negativos: {neg}, Positivos: {pos}, scale_pos_weight: {scale:.2f}\")\n",
        "\n",
        "# Modelo con ajuste por desbalance y regularizaci√≥n\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=4,\n",
        "    random_state=42,\n",
        "    eval_metric=\"logloss\",\n",
        "    scale_pos_weight=scale,   # üëà desbalance\n",
        "    reg_lambda=1.0,           # üëà regularizaci√≥n L2 (default=1.0)\n",
        "    reg_alpha=0.1             # üëà regularizaci√≥n L1 (default=0.0, aqu√≠ lo activamos)\n",
        ")\n",
        "\n",
        "\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred = xgb.predict(X_test)\n",
        "y_proba = xgb.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_proba))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14144ce9-7efd-450a-bdfb-276a061a5a4e",
      "metadata": {
        "id": "14144ce9-7efd-450a-bdfb-276a061a5a4e"
      },
      "source": [
        "## Explicaci√≥n del c√≥digo\n",
        "\n",
        "---\n",
        "\n",
        "### 1) Calcular el ratio de desbalance\n",
        "\n",
        "```python\n",
        "neg, pos = np.bincount(y_train)\n",
        "scale = neg / pos\n",
        "print(f\"Negativos: {neg}, Positivos: {pos}, scale_pos_weight: {scale:.2f}\")\n",
        "```\n",
        "\n",
        "* `np.bincount(y_train)` cuenta cu√°ntas instancias hay de la clase **0** (*neg*) y de la clase **1** (*pos*).\n",
        "\n",
        "  > Requisito: `y_train` debe ser binaria con etiquetas **0/1**. Si no lo es, convi√©rtelas (p. ej., con `LabelEncoder`).\n",
        "* `scale = neg / pos` calcula el **ratio** entre clases.\n",
        "\n",
        "  * Si hay muchos m√°s 0 que 1, `scale` ser√° grande ‚Üí se **aumenta el peso** de los positivos en el entrenamiento.\n",
        "* Este valor se usa en `scale_pos_weight` (ver abajo).\n",
        "\n",
        "**¬øPor qu√© sirve?**\n",
        "En datasets desbalanceados, el modelo puede ‚Äúignorar‚Äù la clase minoritaria. `scale_pos_weight` **repondera** la p√©rdida para que los positivos ‚Äúpesen‚Äù m√°s, ayudando a detectar la clase rara (p. ej., *default*).\n",
        "\n",
        "---\n",
        "\n",
        "### 2) Modelo con ajuste por desbalance y regularizaci√≥n\n",
        "\n",
        "```python\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=4,\n",
        "    random_state=42,\n",
        "    eval_metric=\"logloss\",\n",
        "    scale_pos_weight=scale,   # üëà desbalance\n",
        "    reg_lambda=1.0,           # üëà L2 (default=1.0)\n",
        "    reg_alpha=0.1             # üëà L1 (default=0.0, aqu√≠ lo activamos)\n",
        ")\n",
        "```\n",
        "\n",
        "* **`scale_pos_weight=scale`**: pondera m√°s la **clase positiva (1)** en la funci√≥n de p√©rdida. Regla pr√°ctica: `neg/pos`.\n",
        "\n",
        "  * √ötil cuando **pos** ‚â™ **neg**.\n",
        "  * Alternativa: pasar **`sample_weight`** por instancia al `fit` si quieres pesos m√°s finos.\n",
        "* **Regularizaci√≥n**: controla la **complejidad** del ensemble para evitar **overfitting**.\n",
        "\n",
        "  * `reg_lambda` (**L2**): reduce magnitudes de los pesos en las hojas ‚Üí suaviza el modelo.\n",
        "  * `reg_alpha` (**L1**): favorece **sparsidad** (muchos pesos = 0) ‚Üí simplifica y puede mejorar interpretabilidad.\n",
        "* Otros hiperpar√°metros (ya configurados):\n",
        "\n",
        "  * `n_estimators=200` y `learning_rate=0.1`: m√°s √°rboles + pasos peque√±os ‚Üí aprendizaje m√°s estable.\n",
        "  * `max_depth=4`: √°rboles poco profundos reducen el riesgo de sobreajuste en tabulares.\n",
        "  * `eval_metric=\"logloss\"`: p√©rdida logar√≠tmica binaria para seguimiento del entrenamiento.\n",
        "\n",
        "> Tip de pr√°ctica: afina `scale_pos_weight`, `reg_lambda`, `reg_alpha`, `max_depth`, `min_child_weight`, `subsample`, `colsample_bytree` con **validaci√≥n cruzada** o **early stopping**.\n",
        "\n",
        "---\n",
        "\n",
        "### 3) Entrenamiento y predicci√≥n\n",
        "\n",
        "```python\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred  = xgb.predict(X_test)\n",
        "y_proba = xgb.predict_proba(X_test)[:,1]\n",
        "```\n",
        "\n",
        "* `fit`: entrena el ensemble de √°rboles.\n",
        "* `predict`: devuelve etiquetas 0/1 usando umbral 0.5 por defecto.\n",
        "* `predict_proba` (columna `[:,1]`): devuelve **probabilidades** de clase positiva. √ötil para m√©tricas umbral-dependientes, **ROC/PR**, *calibration*, y para ajustar el umbral seg√∫n costos de negocio.\n",
        "\n",
        "> Tip: En problemas desbalanceados, **no quedarse con el umbral 0.5**. Eliger uno que optimice una m√©trica objetivo (ej., **F1**, **Recall\\@Precision**, **Expected cost**).\n",
        "\n",
        "---\n",
        "\n",
        "### 4) Evaluaci√≥n\n",
        "\n",
        "```python\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_proba))\n",
        "```\n",
        "\n",
        "* `classification_report`: precisi√≥n, recall y F1 por clase (basadas en **y\\_pred** ‚Üí dependen del **umbral**).\n",
        "* `roc_auc_score`: AUC-ROC sobre **probabilidades** (**y\\_proba**).\n",
        "\n",
        "  * **AUC** no depende del umbral y mide la **capacidad discriminativa** global del modelo.\n",
        "  * En banca, suele complementarse con **KS**, **Gini** y **PR AUC** si hay fuerte desbalance.\n",
        "\n",
        "---\n",
        "\n",
        "### Buenas pr√°cticas y mejoras r√°pidas\n",
        "\n",
        "1. **Early Stopping** (evita sobreajuste y ahorra c√≥mputo):\n",
        "\n",
        "```python\n",
        "xgb.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    early_stopping_rounds=50,      # detiene si no mejora\n",
        "    verbose=False\n",
        ")\n",
        "```\n",
        "\n",
        "2. **B√∫squeda de umbral √≥ptimo** (ejemplo con F1):\n",
        "\n",
        "```python\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "probas = y_proba\n",
        "ths = np.linspace(0.01, 0.99, 99)\n",
        "f1s = [f1_score(y_test, (probas >= t).astype(int)) for t in ths]\n",
        "best_t = ths[int(np.argmax(f1s))]\n",
        "print(f\"Mejor umbral por F1: {best_t:.2f}, F1={max(f1s):.3f}\")\n",
        "```\n",
        "\n",
        "3. **Cu√°ndo usar `scale_pos_weight`**\n",
        "\n",
        "* √ösar cuando **pos** ‚â™ **neg**. Si hay **pesos por instancia** (costos diferentes), considera `sample_weight` en `fit`.\n",
        "* Evitar **mezclar** `scale_pos_weight` con otra l√≥gica de pesos que duplique el efecto (p. ej., `sample_weight` ya desbalanceado) salvo que lo hagas intencionalmente.\n",
        "\n",
        "4. **Sanity checks**\n",
        "\n",
        "* Verificar que `pos > 0` (si no, `neg/pos` explota).\n",
        "* Si las etiquetas no son 0/1, normalizarlas antes de `bincount`.\n",
        "\n",
        "---\n",
        "\n",
        "### Resumen\n",
        "\n",
        "* Se calcula el **ratio de clases** para informar al modelo del desbalance (`scale_pos_weight`).\n",
        "* Se a√±ade **regularizaci√≥n L1/L2** para **controlar complejidad** y **evitar overfitting**.\n",
        "* Se eval√∫a con **m√©tricas por probabilidad (AUC)** y por etiqueta (report), recordando que el **umbral** es clave en desbalance.\n",
        "* Considerar **early stopping** y **b√∫squeda de umbral** para mejores resultados pr√°cticos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad20b82-dd7a-4a68-ba91-3939f74abeb1",
      "metadata": {
        "id": "3ad20b82-dd7a-4a68-ba91-3939f74abeb1"
      },
      "outputs": [],
      "source": [
        "# === Matriz de confusi√≥n ===\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.xlabel(\"Predicci√≥n\")\n",
        "plt.ylabel(\"Valor real\")\n",
        "plt.title(\"Matriz de confusi√≥n\")\n",
        "plt.show()\n",
        "\n",
        "# === Curva ROC ===\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f\"XGBClassifier (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\")  # l√≠nea diagonal\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Curva ROC\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f36274fa-1297-4cab-afb1-81df016f0799",
      "metadata": {
        "id": "f36274fa-1297-4cab-afb1-81df016f0799"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# Importancia de variables (built-in de XGBoost)\n",
        "# kinds disponibles: \"weight\", \"gain\", \"cover\", \"total_gain\", \"total_cover\"\n",
        "# =========================================================\n",
        "\n",
        "# Asignar nombres al booster (si X_train era ndarray)\n",
        "booster = xgb.get_booster()\n",
        "booster.feature_names = feature_names\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plot_importance(xgb, importance_type=\"gain\", max_num_features=20)\n",
        "plt.title(\"Importancia de variables (gain) - XGBoost\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57ebd35-6e25-4d89-8771-68ca94b1c649",
      "metadata": {
        "id": "e57ebd35-6e25-4d89-8771-68ca94b1c649"
      },
      "outputs": [],
      "source": [
        "# SHAP values v√≠a XGBoost (pred_contribs=True) y gr√°fico de barras por mean |SHAP|\n",
        "# - Usamos DMatrix para garantizar los nombres\n",
        "\n",
        "dtest = DMatrix(X_test, feature_names=feature_names)\n",
        "shap_values_full = booster.predict(dtest, pred_contribs=True)  # (n_samples, n_features + 1) incluye bias\n",
        "shap_values = shap_values_full[:, :-1]  # quitamos bias\n",
        "\n",
        "mean_abs_shap = np.mean(np.abs(shap_values), axis=0)\n",
        "order = np.argsort(mean_abs_shap)[::-1]\n",
        "top_k = min(20, len(feature_names))\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.barh(np.array(feature_names)[order[:top_k]][::-1], mean_abs_shap[order[:top_k]][::-1])\n",
        "plt.xlabel(\"Mean |SHAP value|\")\n",
        "plt.title(\"Importancia (media de |SHAP|) - Top features\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3af9e549-ec7c-4352-b111-770645b0f1bd",
      "metadata": {
        "id": "3af9e549-ec7c-4352-b111-770645b0f1bd"
      },
      "source": [
        "## üîπ ¬øQu√© es un **Beeswarm plot** en SHAP?\n",
        "\n",
        "El **Beeswarm plot** es el gr√°fico **resumen m√°s usado en SHAP**.\n",
        "Muestra, en **una sola figura**, c√≥mo todas las variables influyen en las predicciones de un modelo.\n",
        "\n",
        "Es una **visualizaci√≥n compacta y global** de los SHAP values.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ ¬øC√≥mo se interpreta?\n",
        "\n",
        "1. **Eje Y (vertical):** lista de variables, ordenadas de arriba hacia abajo por **importancia global** (media del valor absoluto de SHAP).\n",
        "2. **Eje X (horizontal):** valor SHAP ‚Üí cu√°nto aporta la variable a la predicci√≥n.\n",
        "\n",
        "   * Valores positivos ‚Üí empujan la predicci√≥n hacia arriba (ej. mayor riesgo de default).\n",
        "   * Valores negativos ‚Üí empujan la predicci√≥n hacia abajo (ej. menor riesgo de default).\n",
        "3. **Cada punto** = una observaci√≥n (fila del dataset).\n",
        "4. **Color del punto:** representa el valor real de la feature (bajo ‚Üí azul, alto ‚Üí rojo). Esto permite ver **patrones**:\n",
        "\n",
        "   * Ejemplo: si para *edad*, los puntos rojos (edades altas) tienen SHAP negativo, significa que **edad alta disminuye el riesgo**.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ ¬øPor qu√© se llama ‚ÄúBeeswarm‚Äù?\n",
        "\n",
        "Porque al juntar miles de puntos de distintas observaciones en una sola figura, parecen un **enjambre de abejas** alrededor de cada variable.\n",
        "Los puntos se distribuyen horizontalmente para no superponerse, creando esa apariencia.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Ventajas del Beeswarm plot\n",
        "\n",
        "* Resume toda la informaci√≥n en un solo gr√°fico.\n",
        "* Permite ver **importancia global** y tambi√©n **efectos locales** de cada variable.\n",
        "* Muestra **no linealidades** y **direcci√≥n del impacto**.\n",
        "* Mucho m√°s informativo que un simple ranking de importancias.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **En resumen:**\n",
        "El **Beeswarm plot en SHAP** es una representaci√≥n visual que combina importancia de variables y efecto individual de cada observaci√≥n, mostrando tanto la magnitud como la direcci√≥n de la contribuci√≥n de cada feature al modelo.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cf18060-787e-48f8-8063-559b8652ff86",
      "metadata": {
        "id": "8cf18060-787e-48f8-8063-559b8652ff86"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "explainer = shap.TreeExplainer(xgb.get_booster())\n",
        "shap_values_shap = explainer.shap_values(X_test)\n",
        "\n",
        "# --- Beeswarm ---\n",
        "shap.summary_plot(shap_values_shap, X_test, feature_names=feature_names, show=False)\n",
        "\n",
        "plt.title(\"SHAP Values - Beeswarm\", fontsize=14)  # üëà t√≠tulo sobre el gr√°fico\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea225070-3c13-4847-bd85-b9ec10c8e5d9",
      "metadata": {
        "id": "ea225070-3c13-4847-bd85-b9ec10c8e5d9"
      },
      "source": [
        "## üîπ ¬øQu√© es un *force plot* en SHAP?\n",
        "\n",
        "El **force plot** es una de las visualizaciones cl√°sicas de **SHAP (SHapley Additive exPlanations)**.\n",
        "Sirve para mostrar, en una sola observaci√≥n (una fila de tu dataset), **c√≥mo cada variable contribuye a empujar la predicci√≥n** de tu modelo hacia arriba o hacia abajo respecto al valor base (*expected value*).\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Conceptos clave\n",
        "\n",
        "* **Expected Value (valor base):**\n",
        "  Es el valor promedio del modelo antes de ver ninguna caracter√≠stica (ejemplo: la probabilidad media de la clase positiva en el dataset).\n",
        "\n",
        "* **SHAP values:**\n",
        "  Para cada feature, indica si esa variable **aumenta** o **disminuye** la predicci√≥n respecto al expected value.\n",
        "\n",
        "  * Valores SHAP positivos ‚Üí empujan la predicci√≥n hacia la clase positiva (mayor probabilidad de default, churn, etc.).\n",
        "  * Valores SHAP negativos ‚Üí empujan hacia la clase negativa.\n",
        "\n",
        "* **Predicci√≥n final:**\n",
        "  Se obtiene sumando el expected value + la suma de todos los SHAP values de esa instancia.\n",
        "\n",
        "---\n",
        "\n",
        "### üîé ¬øC√≥mo se interpreta el gr√°fico?\n",
        "\n",
        "En el force plot:\n",
        "\n",
        "* Hay una **barra horizontal** que representa el valor base al inicio y la predicci√≥n final al final.\n",
        "* Cada feature aparece como una \"fuerza\":\n",
        "\n",
        "  * **Rojo (‚Üí)**: empuja la predicci√≥n hacia arriba (hacia 1 en binario).\n",
        "  * **Azul (‚Üê)**: empuja hacia abajo (hacia 0 en binario).\n",
        "\n",
        "Es como una balanza de fuerzas: cada variable suma o resta hasta alcanzar la probabilidad final que da el modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### üìä Ejemplo pr√°ctico en tu caso (Bank Marketing)\n",
        "\n",
        "Si la predicci√≥n es que un cliente **s√≠ suscribir√° un dep√≥sito**:\n",
        "\n",
        "* Variables como `contact=cellular`, `month=mar`, `duration=longa llamada` pueden aparecer en rojo ‚Üí empujando hacia **s√≠**.\n",
        "* Variables como `age=young`, `previous=0`, `poutcome=unknown` pueden aparecer en azul ‚Üí empujando hacia **no**.\n",
        "\n",
        "As√≠ pod√©s ver **qu√© combinaci√≥n espec√≠fica de factores llev√≥ a la decisi√≥n del modelo para ese cliente**.\n",
        "\n",
        "---\n",
        "\n",
        "üëâ Resumen:\n",
        "El **force plot** es una visualizaci√≥n **individual** que explica **c√≥mo cada feature influy√≥ en la predicci√≥n de un caso particular**, mostrando de manera gr√°fica las fuerzas que llevan desde el promedio (expected value) hasta la predicci√≥n final.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c421556-d871-4e6a-a05f-9427d0ce1b98",
      "metadata": {
        "id": "7c421556-d871-4e6a-a05f-9427d0ce1b98"
      },
      "outputs": [],
      "source": [
        "## Force plot individual con SHAP (XGBoost)\n",
        "\n",
        "# Elegimos un √≠ndice del test (ej. la primera fila)\n",
        "i = 0\n",
        "\n",
        "# Extraer valores de la fila y sus SHAP values\n",
        "x_row = X_test.iloc[i]\n",
        "shap_row = shap_values_shap[i]\n",
        "\n",
        "# Inicializar visualizaci√≥n interactiva de SHAP\n",
        "shap.initjs()\n",
        "\n",
        "# Force plot para la instancia i\n",
        "shap.force_plot(\n",
        "    base_value=explainer.expected_value,  # valor base (expected value)\n",
        "    shap_values=shap_row,                 # contribuciones SHAP de la fila\n",
        "    features=x_row,                       # valores de las features de esa fila\n",
        "    feature_names=feature_names,          # opcional si quer√©s mostrar nombres expl√≠citos\n",
        "    matplotlib=True                      # interactivo en notebook (True = gr√°fico est√°tico)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6f0e60b-1f2f-49d8-8153-ae040418e48e",
      "metadata": {
        "id": "a6f0e60b-1f2f-49d8-8153-ae040418e48e"
      },
      "source": [
        "## üîπ ¬øQu√© es un **Dependence Plot** en SHAP?\n",
        "\n",
        "Un **Dependence Plot** es un gr√°fico que muestra **c√≥mo influye una variable en las predicciones del modelo seg√∫n sus valores**, usando los **SHAP values** como medida de impacto.\n",
        "\n",
        "* En el eje **X** se representa el valor real de la **feature**.\n",
        "* En el eje **Y** se representa el **SHAP value** de esa feature, es decir, cu√°nto aporta (positivo o negativo) al resultado del modelo.\n",
        "* Cada punto es una observaci√≥n del dataset (una fila).\n",
        "\n",
        "üëâ La interpretaci√≥n es intuitiva:\n",
        "\n",
        "* **Si los SHAP values son positivos** ‚Üí esa variable aumenta la probabilidad/predicci√≥n del modelo.\n",
        "* **Si los SHAP values son negativos** ‚Üí esa variable reduce la predicci√≥n.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Caracter√≠sticas principales\n",
        "\n",
        "1. **Relaci√≥n variable-predicci√≥n**: muestra c√≥mo los cambios en una feature modifican la salida del modelo.\n",
        "2. **No linealidad**: a diferencia de modelos lineales, se pueden observar curvas, umbrales y patrones complejos.\n",
        "3. **Coloraci√≥n opcional**: muchas veces los puntos se colorean por otra feature correlacionada, lo que ayuda a descubrir **interacciones entre variables**.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Ejemplo pr√°ctico\n",
        "\n",
        "Si analizamos un modelo de riesgo de cr√©dito y hacemos un dependence plot de la variable **‚Äúingresos‚Äù**:\n",
        "\n",
        "* Eje X ‚Üí valores de ingresos de los clientes.\n",
        "* Eje Y ‚Üí SHAP values de ingresos.\n",
        "* Si observamos que **a bajos ingresos los SHAP values son positivos**, significa que bajos ingresos **aumentan la probabilidad de default** en la predicci√≥n del modelo.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ Resumen:\n",
        "Un **Dependence Plot** con SHAP es como una **‚Äúcurva de efecto‚Äù** que explica c√≥mo el modelo utiliza una variable para tomar decisiones, revelando patrones e interacciones que un simple ranking de importancia no muestra.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b88d91-8d8a-42ec-b9d9-d7cf9b1a6191",
      "metadata": {
        "id": "f4b88d91-8d8a-42ec-b9d9-d7cf9b1a6191"
      },
      "outputs": [],
      "source": [
        "# Dependence plot de la feature m√°s importante\n",
        "top_feat_idx = order[0]\n",
        "if hasattr(X_test, \"iloc\"):\n",
        "    x_vals = X_test.iloc[:, top_feat_idx].to_numpy()\n",
        "else:\n",
        "    x_vals = X_test[:, top_feat_idx]\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(x_vals, shap_values[:, top_feat_idx], s=12, alpha=0.6)\n",
        "plt.xlabel(feature_names[top_feat_idx])\n",
        "plt.ylabel(\"SHAP value\")\n",
        "plt.title(f\"Dependence plot (SHAP) - {feature_names[top_feat_idx]}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d863016-c08e-4bbd-a90e-952799507364",
      "metadata": {
        "id": "1d863016-c08e-4bbd-a90e-952799507364"
      },
      "source": [
        "---\n",
        "\n",
        "## 5. Preguntas de Discusi√≥n\n",
        "\n",
        "### 1. ¬øQu√© ventajas ofrece XGBoost frente a modelos lineales en datos tabulares?\n",
        "\n",
        "* **Relaciones no lineales:** mientras que los modelos lineales (como regresi√≥n log√≠stica) asumen una relaci√≥n lineal entre variables y resultado, XGBoost puede capturar interacciones complejas y no lineales.\n",
        "* **Ingenier√≠a de caracter√≠sticas impl√≠cita:** los √°rboles crean autom√°ticamente combinaciones y umbrales de variables, sin necesidad de transformar mucho los datos de entrada.\n",
        "* **Manejo de valores at√≠picos y escalamiento:** no requiere normalizaci√≥n y es m√°s robusto frente a outliers.\n",
        "* **Regularizaci√≥n incorporada:** incluye par√°metros de penalizaci√≥n (`lambda`, `alpha`) para controlar la complejidad y reducir el riesgo de sobreajuste.\n",
        "* **Escalabilidad y velocidad:** est√° optimizado en C++ con paralelizaci√≥n y t√©cnicas como ‚Äútree boosting‚Äù y ‚Äúcolumn block structure‚Äù, lo que lo hace muy eficiente para datasets grandes.\n",
        "* **Importancia de variables y explicabilidad:** provee m√©tricas de importancia y puede complementarse f√°cilmente con SHAP values para interpretar los modelos.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. ¬øC√≥mo influye el hiperpar√°metro `max_depth` en el overfitting?\n",
        "\n",
        "* `max_depth` controla la **profundidad m√°xima de los √°rboles** en el ensemble.\n",
        "* **Profundidad baja (ej. 2‚Äì4):**\n",
        "\n",
        "  * Los √°rboles son simples, con menor riesgo de sobreajuste.\n",
        "  * El modelo puede quedarse corto y subestimar patrones (underfitting).\n",
        "* **Profundidad alta (ej. 8‚Äì15):**\n",
        "\n",
        "  * Los √°rboles capturan muchos detalles, incluso ruido.\n",
        "  * Aumenta el riesgo de overfitting, sobre todo en datasets peque√±os o con ruido.\n",
        "* En la pr√°ctica:\n",
        "\n",
        "  * Se combina con otros par√°metros (`min_child_weight`, `subsample`, `colsample_bytree`) para equilibrar sesgo y varianza.\n",
        "  * Lo habitual en datos tabulares est√° entre 3 y 6.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. ¬øQu√© m√©tricas usar√≠as en un banco para evaluar un modelo de default?\n",
        "\n",
        "En problemas de riesgo crediticio, el costo de un error no es sim√©trico: **dar cr√©dito a alguien que incumple es mucho m√°s costoso** que rechazar un buen cliente. Por eso se usan varias m√©tricas:\n",
        "\n",
        "* **AUC-ROC:** mide la capacidad discriminativa del modelo para separar ‚Äúdefault‚Äù de ‚Äúno default‚Äù.\n",
        "* **Gini coefficient:** derivado del AUC, muy usado en la industria bancaria para evaluar modelos de scoring.\n",
        "* **KS Statistic (Kolmogorov‚ÄìSmirnov):** mide la separaci√≥n entre las distribuciones de score de clientes buenos y malos.\n",
        "* **Precision-Recall (AUC-PR):** √∫til cuando hay desbalance (pocos clientes en default).\n",
        "* **Matriz de confusi√≥n y m√©tricas asociadas:**\n",
        "\n",
        "  * **Recall (sensibilidad):** minimizar falsos negativos (detectar la mayor√≠a de los defaulters).\n",
        "  * **Precision:** evitar marcar como defaulters a demasiados buenos clientes.\n",
        "* **M√©tricas de negocio/costo:** cada banco puede definir un ‚Äúexpected loss‚Äù o funci√≥n de costos que penaliza m√°s los falsos negativos que los falsos positivos.\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}