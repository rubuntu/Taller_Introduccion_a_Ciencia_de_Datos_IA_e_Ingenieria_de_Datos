{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubuntu/Taller_Introduccion_a_Ciencia_de_Datos_IA_e_Ingenieria_de_Datos/blob/main/sesion_09_comparacion_con_regresion_logistica_y_evaluacion_de_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "020205e3",
      "metadata": {
        "id": "020205e3"
      },
      "source": [
        "# Sesi√≥n 09: Comparaci√≥n con Regresi√≥n Log√≠stica y Evaluaci√≥n de Modelos\n",
        "\n",
        "## Objetivos\n",
        "- Entrenar un modelo de regresi√≥n log√≠stica como baseline.\n",
        "- Comparar m√©tricas con XGBoost y CatBoost.\n",
        "- Discutir implicaciones pr√°cticas en banca.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Regresi√≥n Log√≠stica Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94d647d4-5556-4101-8023-1150df4df254",
      "metadata": {
        "id": "94d647d4-5556-4101-8023-1150df4df254"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from xgboost import XGBClassifier, plot_importance, DMatrix\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Verificar si catboost est√° instalado, si no instalarlo\n",
        "try:\n",
        "    from catboost import CatBoostClassifier\n",
        "    #print(\"‚úÖ CatBoost ya est√° instalado\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è CatBoost no est√° instalado. Instalando ahora...\")\n",
        "    !pip install -q catboost > /dev/null\n",
        "    from catboost import CatBoostClassifier\n",
        "    print(\"‚úÖ CatBoost instalado correctamente\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "441ac9fb-cda6-4e1a-bac6-0f0518bd0691",
      "metadata": {
        "id": "441ac9fb-cda6-4e1a-bac6-0f0518bd0691"
      },
      "outputs": [],
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\"\n",
        "df = pd.read_excel(url, header=1)\n",
        "\n",
        "df.rename(columns={\"default payment next month\": \"default\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5795338c-9fea-415c-8956-1481143e0ee7",
      "metadata": {
        "id": "5795338c-9fea-415c-8956-1481143e0ee7"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=[\"ID\",\"default\"])\n",
        "y = df[\"default\"]\n",
        "\n",
        "# Seleccionamos solo las columnas num√©ricas\n",
        "numericas = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Inicializamos el scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajustamos y transformamos\n",
        "X_scaled = X.copy()\n",
        "X_scaled[numericas] = scaler.fit_transform(X[numericas])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99fd39de",
      "metadata": {
        "id": "99fd39de"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = logreg.predict(X_test)\n",
        "y_proba_lr = logreg.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_proba_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f712d88",
      "metadata": {
        "id": "0f712d88"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. Comparaci√≥n de Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f21f867a-d1cd-4736-87a3-6a811a116220",
      "metadata": {
        "id": "f21f867a-d1cd-4736-87a3-6a811a116220"
      },
      "outputs": [],
      "source": [
        "# Calcular el ratio\n",
        "neg, pos = np.bincount(y_train)\n",
        "scale = neg / pos\n",
        "\n",
        "# Modelo con ajuste por desbalance y regularizaci√≥n\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=4,\n",
        "    random_state=42,\n",
        "    eval_metric=\"logloss\",\n",
        "    scale_pos_weight=scale,   # üëà desbalance\n",
        "    reg_lambda=1.0,           # üëà regularizaci√≥n L2 (default=1.0)\n",
        "    reg_alpha=0.1             # üëà regularizaci√≥n L1 (default=0.0, aqu√≠ lo activamos)\n",
        ")\n",
        "\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "y_proba_xgb = xgb.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_proba_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0be6e208-1702-4602-968d-a4cb31425000",
      "metadata": {
        "id": "0be6e208-1702-4602-968d-a4cb31425000"
      },
      "outputs": [],
      "source": [
        "cat = CatBoostClassifier(\n",
        "    iterations=200,\n",
        "    depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_seed=42,\n",
        "    verbose=50,\n",
        "    loss_function=\"Logloss\",   # lo que se optimiza\n",
        "    eval_metric=\"AUC\",         # lo que se usa para seleccionar el \"best iteration\"\n",
        "    auto_class_weights=\"Balanced\",\n",
        "    early_stopping_rounds=100,  # ‚ö° se detiene si no mejora en 100 iteraciones\n",
        ")\n",
        "\n",
        "cat.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_test, y_test),\n",
        "    use_best_model=True,\n",
        "    #plot=True\n",
        ")\n",
        "\n",
        "y_pred_cat = cat.predict(X_test)\n",
        "y_proba_cat = cat.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(classification_report(y_test, y_pred_cat))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_proba_cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17897691",
      "metadata": {
        "id": "17897691"
      },
      "outputs": [],
      "source": [
        "results = {\n",
        "    \"Logistic Regression\": roc_auc_score(y_test, y_proba_lr),\n",
        "    \"XGBoost\": roc_auc_score(y_test, xgb.predict_proba(X_test)[:,1]),\n",
        "    \"CatBoost\": roc_auc_score(y_test, cat.predict_proba(X_test)[:,1])\n",
        "}\n",
        "\n",
        "import pandas as pd\n",
        "print(pd.DataFrame(results, index=[\"AUC\"]).T)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14297394",
      "metadata": {
        "id": "14297394"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Interpretaci√≥n en Contexto Bancario\n",
        "\n",
        "* **Regresi√≥n log√≠stica**: m√°s interpretable, √∫til para auditor√≠a/regulaci√≥n.\n",
        "* **XGBoost / CatBoost**: mejor performance, √∫til en scoring de riesgo real.\n",
        "* Elecci√≥n depende del trade-off entre **precisi√≥n vs explicabilidad**.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Visualizaci√≥n de Importancia de Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23caf6b2-8ca2-4878-8e63-369d07eb4015",
      "metadata": {
        "id": "23caf6b2-8ca2-4878-8e63-369d07eb4015"
      },
      "outputs": [],
      "source": [
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "idx = np.arange(len(feature_names))\n",
        "\n",
        "ax1.bar(idx - 0.2, xgb_feat, width=0.4, label=\"XGBoost (0‚Äì1)\", alpha=0.7)\n",
        "ax2.bar(idx + 0.2, cat_feat, width=0.4, label=\"CatBoost (0‚Äì100)\", alpha=0.5, color=\"tab:orange\")\n",
        "\n",
        "ax1.set_xticks(idx)\n",
        "ax1.set_xticklabels(feature_names, rotation=45, ha=\"right\")\n",
        "ax1.set_ylabel(\"XGBoost (suma=1)\")\n",
        "ax2.set_ylabel(\"CatBoost (suma‚âà100)\")\n",
        "plt.title(\"Importancia de Variables\")\n",
        "fig.tight_layout()\n",
        "fig.legend(loc=\"upper right\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0efc4bc",
      "metadata": {
        "id": "b0efc4bc"
      },
      "source": [
        "## 5. Preguntas de Discusi√≥n\n",
        "\n",
        "### 1. ¬øQu√© m√©trica es m√°s relevante para un banco: AUC, Recall o Precision?\n",
        "\n",
        "* **AUC (Area Under the Curve)** mide la capacidad global del modelo para distinguir entre clases (por ejemplo, buenos vs. malos pagadores). Es √∫til para comparar modelos, pero no dice directamente el costo de errores.\n",
        "* **Recall (Sensibilidad o Tasa de Verdaderos Positivos)** mide cu√°ntos malos pagadores fueron correctamente identificados. Es muy cr√≠tico en banca, porque perder un cliente de alto riesgo (falso negativo) significa p√©rdidas directas.\n",
        "* **Precision (Precisi√≥n o Valor Predictivo Positivo)** mide cu√°ntos de los clientes clasificados como ‚Äúmalos pagadores‚Äù realmente lo son. En banca, baja precisi√≥n implica que estamos rechazando muchos clientes que en realidad pagar√≠an (p√©rdida de negocio).\n",
        "\n",
        "üëâ **Relevancia:**\n",
        "\n",
        "* Para **riesgo crediticio**, normalmente se prefiere **Recall** alto, porque lo m√°s costoso es aprobar a alguien que no va a pagar (falso negativo).\n",
        "* Sin embargo, el banco tambi√©n debe cuidar la **Precision**, porque si rechaza demasiados buenos clientes pierde mercado.\n",
        "* El **AUC** sirve como comparador general de modelos, pero la decisi√≥n de negocio suele ponderar Recall y Precision en funci√≥n de la estrategia del banco.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. ¬øPor qu√© un banco podr√≠a preferir regresi√≥n log√≠stica aunque rinda peor?\n",
        "\n",
        "* **Interpretabilidad:** la regresi√≥n log√≠stica es lineal y sus coeficientes se interpretan como odds ratios, lo que permite explicar f√°cilmente por qu√© un cliente fue aprobado o rechazado. Esto es cr√≠tico por **regulaci√≥n** y para la confianza del negocio.\n",
        "* **Simplicidad:** es m√°s f√°cil de mantener, auditar y comunicar a stakeholders (reguladores, comit√© de riesgos, auditores internos).\n",
        "* **Robustez:** la regresi√≥n log√≠stica es menos propensa a sobreajustar que modelos m√°s complejos (XGBoost, redes neuronales) si los datos no son muy grandes.\n",
        "* **Costos regulatorios:** en muchos pa√≠ses, los reguladores exigen modelos explicables para decisiones crediticias; un ‚Äúblack box‚Äù puede ser problem√°tico.\n",
        "\n",
        "üëâ Aunque XGBoost tenga mejor AUC, el banco podr√≠a preferir regresi√≥n log√≠stica porque **sacrifica algo de performance a cambio de transparencia, auditabilidad y cumplimiento regulatorio**.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. ¬øC√≥mo monitorear√≠as el drift de estos modelos en producci√≥n?\n",
        "\n",
        "Primero: **¬øQu√© es drift?**\n",
        "El **drift** ocurre cuando la distribuci√≥n de los datos de producci√≥n se desv√≠a respecto de los datos usados en el entrenamiento. Esto degrada la performance del modelo con el tiempo. Hay varios tipos:\n",
        "\n",
        "* **Data Drift (o covariate shift):** cambian las distribuciones de las variables de entrada (ejemplo: cambia la proporci√≥n de clientes j√≥venes vs. mayores que piden cr√©dito).\n",
        "* **Concept Drift:** cambia la relaci√≥n entre variables y la etiqueta (ejemplo: antes, cierto nivel de deuda era se√±al de riesgo, pero en crisis econ√≥mica deja de serlo).\n",
        "* **Label Drift:** cambian las proporciones de la variable objetivo (ejemplo: aumenta la tasa real de impagos en la econom√≠a).\n",
        "\n",
        "üëâ **C√≥mo monitorear drift en producci√≥n:**\n",
        "\n",
        "1. **Comparar distribuciones de features:** usar tests estad√≠sticos (Kolmogorov‚ÄìSmirnov, Jensen-Shannon, PSI ‚Äì Population Stability Index) para detectar si las variables de entrada cambiaron.\n",
        "2. **Monitoreo de m√©tricas de performance:** seguir AUC, Recall, Precision en muestras de datos con etiquetas recientes. Si bajan, puede haber concept drift.\n",
        "3. **Alertas tempranas:** implementar dashboards (ej. con EvidentlyAI, Fiddler, MLflow) que automaticen la detecci√≥n de drift y generen alertas.\n",
        "4. **Retraining peri√≥dico:** si el drift persiste, reentrenar con datos recientes para que el modelo se adapte.\n",
        "\n",
        "üëâ En banca, el drift es **cr√≠tico** porque los h√°bitos de pago de los clientes cambian con la econom√≠a, nuevas regulaciones o crisis financieras.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ Resumen:\n",
        "\n",
        "* **M√©trica clave:** Recall (pero sin olvidar Precision).\n",
        "* **Modelo simple:** regresi√≥n log√≠stica se prefiere por interpretabilidad y regulaci√≥n.\n",
        "* **Drift:** desviaci√≥n en datos o relaciones; se monitorea con tests de distribuci√≥n, performance en producci√≥n y retraining peri√≥dico.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8a06206-db7f-4eb2-b283-cdd7bb9f845e",
      "metadata": {
        "id": "f8a06206-db7f-4eb2-b283-cdd7bb9f845e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}